{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_path = os.path.join(os.path.join(os.getcwd(),'Datasets'),'movies_dataset')\n",
    "books_path = os.path.join(os.getcwd(),'Book-Crossing dataset cleaning')\n",
    "\n",
    "user_based_dict_path = os.path.join(movies_path,'utility_matrix_user_based.txt')\n",
    "item_based_dict_path = os.path.join(movies_path,'utility_matrix_item_based.txt')\n",
    "\n",
    "explicit_dict_path_books = os.path.join(books_path,'Explicit.csv')\n",
    "\n",
    "implicit_dict_path_books = os.path.join(books_path,'Implicit.csv')\n",
    "\n",
    "\n",
    "CORES = multiprocessing.cpu_count()\n",
    "cliques = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1\n"
    }
   ],
   "source": [
    "'''\n",
    "with open(user_based_dict_path) as fr:\n",
    "    item_based_utility = json.load(fr)\n",
    "'''   \n",
    " \n",
    "\"\"\" with open(user_based_dict_path) as fr:\n",
    "    user_based_utility = json.load(fr) \"\"\"\n",
    "\n",
    "with open(explicit_dict_path_books) as f:\n",
    "    explicit_user_based_utility = {}\n",
    "    \n",
    "    fields = f.readline().strip().split('\\t') # first line has no data\n",
    "\n",
    "    item_ISBN_unique_index = fields.index('uniqueISBN')+1\n",
    "    user_id_index = fields.index('userId')+1\n",
    "    rating_index = fields.index('bookRating')+1\n",
    "    print(user_id_index)\n",
    "    while(True):\n",
    "        line = f.readline().strip().split('\\t')\n",
    "        if(line == ['']):\n",
    "            break\n",
    "\n",
    "        item_name = line[item_ISBN_unique_index]\n",
    "        user_id = line [user_id_index]\n",
    "        rating = float(line[rating_index])\n",
    "\n",
    "        if(explicit_user_based_utility.get(user_id) == None):\n",
    "            explicit_user_based_utility[user_id] = {}\n",
    "    \n",
    "        explicit_user_based_utility[user_id][item_name] = rating    \n",
    "\n",
    "\n",
    "with open(implicit_dict_path_books) as f:\n",
    "    implicit_user_based_utility = {}\n",
    "    \n",
    "    fields = f.readline().strip().split('\\t') # first line has no data\n",
    "\n",
    "    item_ISBN_unique_index = fields.index('uniqueISBN')+1\n",
    "    user_id_index = fields.index('userId')+1\n",
    "    rating_index = fields.index('bookRating')+1\n",
    "\n",
    "    while(True):\n",
    "        line = f.readline().strip().split('\\t')\n",
    "        if(line == ['']):\n",
    "            break\n",
    "\n",
    "        item_name = line[item_ISBN_unique_index]\n",
    "        user_id = line [user_id_index]\n",
    "        rating = float(line[rating_index])\n",
    "    \n",
    "        if(implicit_user_based_utility.get(user_id) == None):\n",
    "            implicit_user_based_utility[user_id] = {}\n",
    "    \n",
    "        implicit_user_based_utility[user_id][item_name] = rating    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    converts the ratings and the keys of the dictionary\n",
    "    {key1:{key2:rating}} into float\n",
    "\n",
    "    user_based_utility -> {key1:{key2:rating}}\n",
    "\"\"\"\n",
    "def convert_ratings_to_float(user_based_utility):\n",
    "    user_based_correct = {}\n",
    "\n",
    "    for key1 in user_based_utility.keys():\n",
    "        for key2 in user_based_utility[key1].keys():\n",
    "\n",
    "            if('X' == key1[-1] or 'x' == key1[-1]):\n",
    "                key11 = key1[:-1] + '1'\n",
    "            elif( key1 == 'B00009ANY9'):\n",
    "                key11 = '1'\n",
    "            else:\n",
    "                key11 = key1 + '0'\n",
    "            \n",
    "            if('X' == key2[-1] or 'x' == key2[-1]):\n",
    "                key22 = key2[:-1] + '1'\n",
    "            elif( key2 == 'B00009ANY9'):\n",
    "                key22 = '1'\n",
    "            else:\n",
    "                key22 = key2 + '0'\n",
    "\n",
    "            key11 = float(key11)\n",
    "            key22 = float(key22)\n",
    "\n",
    "            if(user_based_correct.get(key11) == None):\n",
    "                user_based_correct[key11] = {}\n",
    "            \n",
    "            user_based_correct[key11][key22] = float(user_based_utility[key1][key2])\n",
    "    \n",
    "    return user_based_correct\n",
    "\n",
    "#user_based_utility = convert_ratings_to_float(user_based_utility) #movies\n",
    "explicit_user_based_utility = convert_ratings_to_float(explicit_user_based_utility)\n",
    "implicit_user_based_utility = convert_ratings_to_float(implicit_user_based_utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items are casted to float\n",
    "\n",
    "# items = np.array(list(item_based_utility.keys())).astype(np.int)\n",
    "\n",
    "# items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Returns a partition of dataset\n",
    "    into num_folds dictionaries\n",
    "\n",
    "    the return is [{key1:{key2:rating}}]\n",
    "\"\"\"\n",
    "def divide_dataset(dataset, num_folds):\n",
    "    folds = [{}]*num_folds\n",
    "\n",
    "    for key1 in dataset.keys():\n",
    "        for key2 in dataset[key1].keys():\n",
    "            rand_index = np.random.randint(num_folds)\n",
    "            \n",
    "            tmp_dict = folds[rand_index]\n",
    "\n",
    "            if(tmp_dict.get(key1) == None):\n",
    "                tmp_dict[key1] = {}\n",
    "            \n",
    "            tmp_dict[key1][key2] = dataset[key1][key2]\n",
    "    \n",
    "    return folds\n",
    "\n",
    "num_folds = 4\n",
    "#folds = divide_dataset(user_based_utility, num_folds) #movies\n",
    "folds_explicit = divide_dataset(explicit_user_based_utility, num_folds)\n",
    "folds_implicit = divide_dataset(implicit_user_based_utility, num_folds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(dicts):\n",
    "    ret = {}\n",
    "\n",
    "    for i in range(len(dicts)):\n",
    "        tmp_dict = dicts[i]\n",
    "        for key1 in tmp_dict.keys():\n",
    "            for key2 in tmp_dict[key1].keys():\n",
    "\n",
    "                if(ret.get(key1)==None):\n",
    "                    ret[key1] = {}\n",
    "                ret[key1][key2] = tmp_dict[key1][key2]\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" train_dict = merge_dicts([fold for fold in folds[:3]])\n",
    "test_dict = folds[3]  \"\"\" #movies\n",
    "\n",
    "\n",
    "train_dict_explicit = merge_dicts([fold for fold in folds_explicit[:3]])\n",
    "test_dict = folds_explicit[3] \n",
    "\n",
    "train_dict_implicit = merge_dicts([fold for fold in folds_explicit[:3]])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Calculates the average value of the \n",
    "    valeues in a\n",
    "\n",
    "    a -> dictionary of non zero values \n",
    "\"\"\"\n",
    "def avg(a):\n",
    "    i=0\n",
    "    tot = 0\n",
    "    for k in a.keys():\n",
    "        i +=1\n",
    "        tot += a.get(k)\n",
    "    \n",
    "    return tot/i\n",
    "\n",
    "\"\"\"\n",
    "    Calculates a new dictionary that for each\n",
    "    non null value of a has that values - const\n",
    "\n",
    "    returns a - const\n",
    "\n",
    "    a -> dictioary of non zero values\n",
    "\"\"\"\n",
    "def scale(a,const):\n",
    "    ret = {}\n",
    "    \n",
    "    for k in a.keys():\n",
    "        ret[k] = a.get(k) - const\n",
    "    \n",
    "    return ret\n",
    "\n",
    "\"\"\"\n",
    "    calculates the norm of a dictionary\n",
    "\n",
    "    a -> dictioary of non zero values\n",
    "\"\"\"\n",
    "def norm (a):\n",
    "    tot = 0\n",
    "    for k in a.keys():\n",
    "        tot += pow(a.get(k),2) \n",
    "\n",
    "    return math.sqrt(tot)\n",
    "\n",
    "\"\"\"\n",
    "    computes the inner product of two dictionaries\n",
    "\n",
    "    a -> dictioary of non zero values\n",
    "    b -> dictioary of non zero values\n",
    "\n",
    "\"\"\"\n",
    "def inner_product(a,b):\n",
    "    tot = 0\n",
    "    for k in a.keys():\n",
    "        b_tmp = b.get(k)\n",
    "        if(b_tmp != None):\n",
    "            tot += b_tmp * a.get(k) \n",
    "\n",
    "    return tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Calculates the correlation coefficent\n",
    "        between two vectors\n",
    "    \n",
    "    a, b dictionaries of non zero values\n",
    "\n",
    "    esplicit -> boolean value that  defines if we\n",
    "    need to scale or not cause in the case of implicit\n",
    "    we do not need to scale\n",
    "\"\"\"\n",
    "def compute_correlation_coefficent(a,b, is_explicit):\n",
    "\n",
    "    a_scaled = a\n",
    "    b_scaled = b\n",
    "\n",
    "    if(is_explicit):\n",
    "        avg_a = avg(a)\n",
    "        avg_b = avg(b)\n",
    "\n",
    "        a_scaled = scale(a, avg_a)\n",
    "        b_scaled = scale(b, avg_b)\n",
    "\n",
    "    a_scaled_norm = norm(a_scaled)\n",
    "    b_scaled_norm = norm(b_scaled)\n",
    "\n",
    "    if(a_scaled_norm == 0 or b_scaled_norm == 0):\n",
    "        print('One of the two vectors has 0 norm, returning 0.')\n",
    "        return 0 \n",
    "\n",
    "    sim = inner_product(a_scaled,b_scaled)/(a_scaled_norm*b_scaled_norm)\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputeCorrelationCoefficentThread (threading.Thread):\n",
    "   \"\"\"\n",
    "      user_dict -> dictionary of the user: {itemID:rating}\n",
    "      user_ids -> set of users IDs\n",
    "      utility_matrix -> dataset\n",
    "      is_explicit -> boolean value that  defines if we\n",
    "         need to scale or not cause in the case of implicit\n",
    "         we do not need to scale\n",
    "   \"\"\"\n",
    "   def __init__(self, user_dict, user_ids, utility_matrix, is_explicit, name = None):\n",
    "      threading.Thread.__init__(self)\n",
    "      self.name = name\n",
    "      self.user_dict = user_dict\n",
    "      self.user_ids = user_ids\n",
    "      self.is_explicit = is_explicit\n",
    "      self.utility_matrix = utility_matrix\n",
    "      self.result = None\n",
    "   \n",
    "   def run(self):\n",
    "      if self.name == None:\n",
    "         raise Exception('Something bad happened, thread has no name')\n",
    "      print('Thread {} started'.format(self.name))\n",
    "      self.compute_similarities()\n",
    "\n",
    "   \n",
    "   def compute_similarities(self):\n",
    "      similarities = []\n",
    "      for user in self.user_ids:\n",
    "         tmp_user_dict = self.utility_matrix[user]\n",
    "         similarity = compute_correlation_coefficent(self.user_dict, tmp_user_dict, self.is_explicit)\n",
    "         similarities.append([user,similarity])\n",
    "      \n",
    "      self.result = similarities\n",
    "\n",
    "   # vector of similarities --> [userID, sim_score]\n",
    "   def join(self):\n",
    "        threading.Thread.join(self)\n",
    "        if self.result is not None:\n",
    "            return self.result\n",
    "        else:\n",
    "            print('Error using threads, result is None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    returns a list containing num_folds lists \n",
    "    that are a partition of data\n",
    "\n",
    "    data -> list\n",
    "    num_folds -> number of partitions \n",
    "\"\"\"\n",
    "def make_partitions(num_folds, data):\n",
    "    data_size = len(data)\n",
    "    fold_size = data_size // num_folds\n",
    "    partitions = []\n",
    "    for idx in range(num_folds-1):\n",
    "        partitions.append(data[idx*fold_size:(idx+1)*fold_size])\n",
    "    partitions.append(data[idx*fold_size:])\n",
    "    return partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Returns the clique of the user as np.array\n",
    "\n",
    "    user -> userID\n",
    "    utility_matrix -> {user:{item:rating}}\n",
    "    clique_size -> size of the clique of the user\n",
    "\"\"\"\n",
    "def compute_clique_without_implicit(user, utility_matrix, clique_size):\n",
    "\n",
    "    unique_users = list(set(utility_matrix.keys()))\n",
    "    user_dict = utility_matrix[user]\n",
    "    partitions = make_partitions(CORES,unique_users)    \n",
    "        \n",
    "\n",
    "    threads = []\n",
    "    for idx in range(CORES):\n",
    "        name = \"Thread-{}\".format(idx)\n",
    "        thread = ComputeCorrelationCoefficentThread(name = name, \n",
    "                                                user_dict = user_dict, \n",
    "                                                user_ids = partitions[idx], \n",
    "                                                utility_matrix = utility_matrix, \n",
    "                                                is_explicit = True)\n",
    "        threads.append(thread)\n",
    "\n",
    "    \n",
    "    [thread.start() for thread in threads]    \n",
    "    print('======= all threads started =======')\n",
    "\n",
    "    results = [thread.join() for thread in threads]\n",
    "    print('======= all threads joined =======')\n",
    "    \n",
    "    similarities = []\n",
    "    for elem in results:\n",
    "        for similarity in elem:\n",
    "            similarities.append(similarity)\n",
    "    \n",
    "    similarities = np.array(similarities)\n",
    "    clique = similarities[np.argsort(similarities[:,1])[::-1]][1:clique_size+1]\n",
    "\n",
    "    return clique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    weighted sum of scores of v1 and v2    \n",
    "\n",
    "    v1 -> list [[ID, score]]\n",
    "    v2 -> list [[ID, score]] \n",
    "\n",
    "    a, b weights\n",
    "\"\"\"\n",
    "def sum_vectors(v1, v2, a, b):\n",
    "    ret = []\n",
    "\n",
    "    for idx in range(len(v1)):\n",
    "        if(v1[idx][0]!=v2[idx][0]):\n",
    "            print('The two vectors has to have the same order of users!\\nIf you see this message than you should change the return of ComputeCorrelationCoefficentThread.join() into a dictionary so that I can access the implicit and explicit scores for the same user with a small cost')\n",
    "            raise Exception('The two vectors must have the same order of users!')\n",
    "        \n",
    "        summed_sim = v1[idx][1]*a + v2[idx][1]*b\n",
    "        ret.append([v1[idx][0], summed_sim])\n",
    "        \n",
    "    print(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clique_with_implicit(user, esplicit_utility_matrix, implicit_utility_matrix, clique_size, a, b):\n",
    "\n",
    "    unique_users = list(set(esplicit_utility_matrix.keys()))\n",
    "    user_dict = esplicit_utility_matrix[user]\n",
    "    partitions = make_partitions(CORES,unique_users)    \n",
    "        \n",
    "    print('======= start creating esplicit threads =======')\n",
    "\n",
    "    threads = []\n",
    "    for idx in range(CORES):\n",
    "        name = \"Thread-{}\".format(idx)\n",
    "        thread = ComputeCorrelationCoefficentThread(name = name, \n",
    "                                                user_dict = user_dict, \n",
    "                                                user_ids = partitions[idx], \n",
    "                                                utility_matrix = esplicit_utility_matrix,\n",
    "                                                is_explicit = True)\n",
    "        threads.append(thread)\n",
    "    \n",
    "    [thread.start() for thread in threads]    \n",
    "    print('======= all esplicit threads started =======')\n",
    "\n",
    "    results = [thread.join() for thread in threads]\n",
    "    print('======= all esplicit threads joined =======')\n",
    "    \n",
    "    esplicit_similarities = []\n",
    "    for elem in results:\n",
    "        for similarity in elem:\n",
    "            esplicit_similarities.append(similarity)\n",
    "    \n",
    "    print('======= start creating implicit threads =======')\n",
    "\n",
    "    user_dict = implicit_utility_matrix[user]\n",
    "    threads = []\n",
    "    for idx in range(CORES):\n",
    "        name = \"Thread-{}\".format(idx+CORES)\n",
    "        thread = ComputeCorrelationCoefficentThread(name = name, \n",
    "                                                user_dict = user_dict, \n",
    "                                                user_ids = partitions[idx], \n",
    "                                                utility_matrix = implicit_utility_matrix,\n",
    "                                                is_explicit = False)\n",
    "        threads.append(thread)\n",
    "    \n",
    "    [thread.start() for thread in threads]    \n",
    "    print('======= all implicit threads started =======')\n",
    "\n",
    "    results = [thread.join() for thread in threads]\n",
    "    print('======= all implicit threads joined =======')\n",
    "    \n",
    "    implicit_similarities = []\n",
    "    for elem in results:\n",
    "        for similarity in elem:\n",
    "            implicit_similarities.append(similarity)\n",
    "\n",
    "    similarities = sum_vectors(esplicit_similarities, implicit_similarities, a, b)\n",
    "\n",
    "    similarities = np.array(similarities)\n",
    "    clique = similarities[np.argsort(similarities[:,1])[::-1]][1:clique_size+1]\n",
    "\n",
    "    return clique\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    returns the predicted rating given a user and an item\n",
    "\n",
    "    user -> userID\n",
    "    item -> itemID\n",
    "    clique -> list of users that are similar to userID\n",
    "\"\"\"\n",
    "\n",
    "def predict(user, item, clique, utility_matrix):\n",
    "    numerator = 0\n",
    "    denominator = 0\n",
    "    for elem in clique:\n",
    "        neighbor = elem[0]\n",
    "        similarity = elem[1]\n",
    "\n",
    "        neigh_dict = utility_matrix[neighbor]\n",
    "        rating = neigh_dict.get(item)\n",
    "        \n",
    "        if  rating == None:\n",
    "            continue\n",
    "\n",
    "        numerator += rating*similarity\n",
    "        denominator += similarity\n",
    "    \n",
    "    if denominator == 0:\n",
    "        print('denominator is 0, no user in the clique rated this item')\n",
    "        return -1\n",
    "    \n",
    "    return numerator/denominator\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "340050.0, 0.0], [1372820.0, 0.0], [1241750.0, 0.0], [2388640.0, 0.0], [1274530.0, 0.0], [1438370.0, 0.0], [815780.0, 0.0], [2093730.0, 0.0], [586410.0, 0.0], [357040.0, 0.0], [1045170.0, 0.0], [2093750.0, 0.0], [2421430.0, 0.0], [2781880.0, 0.0], [1700540.0, 0.0], [1798850.0, 0.0], [1012420.0, 0.0], [586440.0, 0.0], [750280.0, 0.0], [160460.0, 0.0], [357070.0, 0.0], [2650830.0, 0.0], [717520.0, 0.0], [2192080.0, 0.0], [2192090.0, 0.0], [2257630.0, 0.0], [979680.0, 0.0], [684780.0, 0.0], [2224880.0, 0.0], [2781940.0, 0.0], [1209080.0, 0.0], [1536760.0, 0.0], [2585340.0, 0.0], [2323200.0, 0.0], [2487040.0, 0.0], [1602310.0, 0.0], [979720.0, 0.0], [1864460.0, 0.0], [2061070.0, 0.0], [848660.0, 0.0], [389910.0, 0.0], [553750.0, 0.0], [2224920.0, 0.0], [2093850.0, 0.0], [1012510.0, 0.0], [1897250.0, 0.0], [2061090.0, 0.0], [324400.0, 0.0], [652080.0, 0.0], [1635120.0, 0.0], [881460.0, 0.0], [2028340.0, 0.0], [1733430.0, 0.0], [357180.0, 0.0], [2159420.0, 0.0], [389950.0, 0.0], [2192190.0, 0.0], [914240.0, 0.0], [2749250.0, 0.0], [1962820.0, 0.0], [2782020.0, 0.07411015162926791], [914250.0, 0.0], [193360.0, 0.0], [258900.0, 0.0], [422740.0, 0.0], [619350.0, 0.0], [324440.0, 0.0], [2552670.0, 0.0], [127840.0, 0.0], [291680.0, 0.0], [815970.0, 0.0], [1766240.0, 0.0], [1831780.0, 0.0], [684910.0, 0.0], [2225010.0, 0.0], [2093940.0, 0.0], [2290550.0, 0.0], [1700730.0, 0.0], [1143680.0, 0.0161943387740922], [1340290.0, 0.0], [1995650.0, 0.0], [2618250.0, 0.0], [2487180.0, 0.0], [1242000.0, 0.0], [455570.0, 0.3111439901828602], [2388890.0, 0.0], [2585500.0, 0.0], [848800.0, 0.0], [1700770.0, 0.0], [2225060.0, 0.0], [2388900.0, 0.0], [62380.0, 0.0], [2552750.0, 0.0], [2716590.0, 0.0], [783280.0, 0.0], [1471410.0, 0.0], [2618290.0, 0.0], [848820.0, 0.0], [1242040.0, 0.0], [1569720.0, 0.0], [1274810.0, 0.0], [2585530.0, 0.0], [2454460.0, 0.0], [1831870.0, 0.0], [226240.0, 0.0], [1733570.0, 0.0], [848840.0, 0.0], [1176520.0, 0.0], [226250.0, 0.056495246811027716], [2290640.0, 0.0], [62420.0, 0.0], [1242070.0, 0.0], [455640.0, 0.0], [816090.0, 0.0], [1209310.0, 0.0], [2192350.0, 0.0], [2356190.0, 0.0], [1143780.0, 0.0], [2487270.0, 0.0], [1143790.0, 0.0], [652280.0, 0.0], [553980.0, 0.0], [1045500.0, 0.0], [1897470.0, 0.0], [2520060.0, 0.0], [1635330.0, 0.0], [2782210.0, 0.0], [553990.0, 0.0], [1635340.0, 0.0], [2651150.0, 0.03647494859656692], [1274900.0, 0.0], [1831960.0, 0.0], [717860.0, 0.0], [881700.0, 0.0], [62510.0, 0.0], [750640.0, 0.0], [1602610.0, 0.0], [914490.0, 0.0], [2552890.0, 0.0], [1832000.0, 0.0], [2716740.0, 0.0], [1471560.0, 0.0], [2290760.0, 0.0], [29770.0, 0.0], [848970.0, 0.0], [1209420.0, 0.0], [193620.0, 0.0], [521300.0, 0.0], [259160.0, 0.0], [652380.0, 0.0], [554080.0, 0.0], [947300.0, 0.0], [849000.0, 0.0], [128110.0, 0.0], [259190.0, 0.0], [1635450.0, 0.0], [2126970.0, 0.0], [160900.0, 0.0], [1668240.0, 0.0], [980120.0, 0.0], [1668250.0, 0.0], [1537180.0, 0.0], [2192540.0, 0.0], [455840.0, 0.0], [1766560.0, 0.0], [1963170.0, 0.0], [717990.0, 0.0], [1537190.0, 0.0], [455850.0, 0.0], [1275050.0, 0.0], [1471660.0, 0.0], [193710.0, 0.0], [718000.0, 0.0], [1373360.0, 0.0], [423090.0, 0.0], [1766580.0, 0.0], [2258100.0, 0.0], [1668280.0, 0.0], [1045690.0, 0.0], [1307840.0, 0.0], [521410.0, 0.0], [2487490.0, 0.0], [554180.0, 0.0], [292040.0, 0.0], [849100.0, 0.0], [1668300.0, 0.0], [881870.0, 0.0], [1537230.0, 0.0], [2192590.0, 0.0], [1635540.0, 0.0], [2192600.0, 0.0], [750810.0, 0.0], [1242330.0, 0.0], [324830.0, 0.0], [849120.0, 0.0], [2323680.0, 0.0], [554210.0, 0.0], [2487520.0, 0.0], [259300.0, 0.0], [2290920.0, 0.0], [128240.0, 0.0], [2159860.0, 0.0], [1078520.0, 0.0], [292090.0, 0.0], [2618620.0, 0.0], [1012990.0, 0.0], [750850.0, 0.0], [2159880.0, 0.0], [1766670.0, 0.0], [1307920.0, 0.0], [2585880.0, 0.0], [1307930.0, 0.0], [2684190.0, 0.0], [1111330.0, 0.0], [161060.0, 0.0], [652580.0, 0.0], [980260.0, 0.0], [750890.0, 0.0], [1013040.0, 0.0], [2028850.0, 0.0], [1275190.0, 0.35323320857153756], [685370.0, 0.0], [1013050.0, 0.0], [423230.0, 0.0], [1144130.0, 0.0], [685380.0, 0.0], [587080.0, 0.0], [161100.0, 0.0], [1144140.0, 0.0], [62800.0, -0.1975915793504099], [2127190.0, 0.0], [128350.0, 0.0], [2749790.0, 0.0], [2782570.0, 0.0], [750960.0, 0.0], [1439090.0, 0.0], [1635700.0, 0.0], [521590.0, 0.0], [1045880.0, 0.0], [1078650.0, 0.0], [2717050.0, 0.0], [1996160.0, 0.0], [1602950.0, 0.0], [2749830.0, 0.0], [554380.0, 0.0], [718220.0, 0.0], [2061710.0, 0.0], [2192780.0, 0.0], [2192800.0, 0.0], [423330.0, 0.0], [1897890.0, 0.0], [1177000.0, 0.0], [1504680.0, 0.0], [554410.0, 0.0], [2717110.0, 0.0], [161210.0, 0.0], [95680.0, 0.0], [2487750.0, 0.0], [2061770.0, 0.0], [1635790.0, 0.0], [30170.0, 0.0], [95710.0, 0.0], [914910.0, 0.0], [1242590.0, 0.0], [2225630.0, 0.0], [816610.0, 0.0], [718310.0, 0.0], [2356710.0, 0.0], [1275370.0, 0.0], [685550.0, 0.0], [554480.0, 0.0], [2094580.0, 0.0], [849400.0, 0.0], [2160120.0, 0.0], [1209850.0, 0.0], [95740.0, 0.0], [1734150.0, 0.0], [2717200.0, 0.0], [161300.0, 0.0], [1144340.0, 0.0], [521750.0, 0.0], [1046040.0, 0.0], [2586140.0, 0.0], [2651680.0, 0.0], [2356770.0, 0.0], [325160.0, 0.0], [2127400.0, 0.0], [357930.0, 0.0], [685610.0, 0.0], [2094640.0, 0.0], [161330.0, 0.0], [1865270.0, 0.0], [620090.0, 0.0], [2422330.0, 0.0], [1668670.0, 0.08434449843555109], [2160190.0, 0.0], [259660.0, 0.0], [816720.0, 0.0], [751190.0, 0.0], [2684510.0, 0.0], [947810.0, 0.0], [1472100.0, 0.0], [1799780.0, 0.0], [1177190.0, 0.0], [2160230.0, 0.0], [2356840.0, 0.0], [1078890.0, 0.0], [2389610.0, 0.0], [292460.0, 0.0], [1111660.0, 0.0], [2586220.0, 0.0], [685680.0, 0.0], [1013360.0, 0.0], [390770.0, 0.0], [882290.0, 0.0], [1865330.0, 0.0], [1996400.0, 0.0], [128630.0, 0.0], [2193010.0, 0.0], [1144440.0, 0.0], [1832570.0, 0.0], [226950.0, 0.0], [2029190.0, 0.0], [2520710.0, 0.0], [1144460.0, 0.0], [2160270.0, 0.0], [1373840.0, 0.0], [1898130.0, 0.0], [489110.0, 0.0], [1406620.0, 0.0], [947870.0, 0.0], [1439390.0, 0.0], [1636000.0, 0.0], [1701540.0, -0.2874344781886402], [194220.0, 0.0], [1701550.0, 0.0], [325300.0, 0.0], [816820.0, 0.0], [1111740.0, 0.0], [718530.0, 0.0], [2062020.0, 0.0], [2422470.0, 0.0], [1144520.0, 0.0], [2291400.0, 0.0], [358090.0, 0.0], [2651850.0, 0.0], [63180.0, 0.0], [2422480.0, 0.0], [1308370.0, 0.0], [1504980.0, 0.0], [390870.0, 0.0], [2062040.0, 0.0], [456410.0, 0.05388183349008156], [2422490.0, 0.0], [1046240.0, 0.0], [259810.0, 0.0], [292590.0, 0.0], [2258670.0, 0.0], [1472240.0, 0.0], [194290.0, 0.0], [685810.0, 0.0], [2488050.0, 0.0], [1275640.0, 0.0], [2750200.0, 0.0], [1341180.0, 0.0], [63230.0, 0.0], [882430.0, 0.0], [1865470.0, 0.0], [521990.0, 0.0], [1603340.0, 0.0], [2094860.0, 0.0], [161550.0, 0.0], [1341200.0, 0.0], [1373970.0, 0.0], [2717460.0, 0.0], [1636120.0, 0.0], [325410.0, 0.0], [1177380.0, 0.0], [2488100.0, 0.0], [2651940.0, 0.0], [423720.0, 0.0], [980780.0, 0.0], [2455340.0, 0.0], [522030.0, 0.0], [1668910.0, 0.0], [882480.0, 0.0], [1931060.0, 0.0], [1308470.0, 0.0], [1177400.0, 0.0], [1505080.0, 0.0], [1668920.0, 0.0], [2193210.0, 0.0], [2357050.0, 0.0], [2619200.0, 0.0], [1832770.0, 0.0], [63300.0, 0.0], [161610.0, 0.0], [489290.0, 0.0], [1537870.0, 0.0], [2717520.0, 0.0], [1144660.0, 0.0], [1800020.0, 0.0], [2488150.0, 0.0], [1046360.0, 0.0], [1111900.0, 0.04820070240589126], [63330.0, 0.0], [1242980.0, 0.0], [554860.0, 0.0], [2029420.0, 0.0], [1898350.0, 0.0], [2062190.0, 0.0], [1603440.0, 0.0], [358260.0, 0.0], [2652020.0, 0.0], [554870.0, 0.0], [259960.0, 0.0], [1570680.0, 0.0], [2553720.0, 0.0], [96130.0, 0.0], [751490.0, 0.0], [1832840.0, 0.0], [2717580.0, 0.0], [2488210.0, 0.0], [2652050.0, 0.0], [391060.0, 0.0], [554900.0, 0.0], [1439640.0, 0.0], [685980.0, 0.0], [587680.0, 0.0], [1275810.0, 0.0], [1439650.0, 0.0], [2422690.0, 0.0], [2783140.0, 0.0], [1177510.0, 0.0], [1832870.0, 0.0], [554920.0, 0.0], [1079210.0, 0.0], [2258860.0, 0.0], [554930.0, 0.08582608035172921], [1537970.0, 0.0], [292790.0, 0.0], [2258870.0, 0.0], [1013690.0, 0.0], [1341370.0, 0.0], [2160570.0, 0.0], [784320.0, 0.0], [1439680.0, 0.0], [1701840.0, 0.0], [948180.0, 0.0], [358360.0, 0.0], [63450.0, 0.0], [1243100.0, 0.05373969135272736], [2226140.0, 0.0], [1865700.0, 0.0], [63470.0, 0.0], [1898480.0, 0.0], [1308660.0, 0.0], [718840.0, 0.0], [2684920.0, 0.0], [784380.0, 0.0], [1144830.0, 0.0], [1406980.0, 0.0], [358410.0, 0.0], [2324490.0, 0.0], [1570830.0, 0.0], [784400.0, 0.0], [1439760.0, 0.0], [2127890.0, 0.0], [358420.0, 0.0], [1603610.0, 0.0], [1701920.0, 0.0], [1046570.0, 0.0], [1931310.0, 0.0], [981040.0, 0.0], [358450.0, 0.0], [1013810.0, 0.0], [2652210.0, 0.0], [1898550.0, 0.0], [2095160.0, 0.0], [325690.0, 0.0], [2291770.0, 0.0], [2029630.0, 0.0], [424000.0, 0.0], [686150.0, 0.0], [2259020.0, 0.0], [1243220.0, 0.0], [784480.0, 0.0], [2127970.0, 0.0], [1669220.0, 0.0], [2586730.0, 0.0], [718970.0, 0.0], [1046650.0, 0.0], [2193530.0, 0.0], [1800320.0, 0.0], [2455680.0, 0.0], [1374340.0, 0.0], [1538180.0, 0.0], [1407110.0, 0.0], [882830.0, 0.0], [424080.0, 0.0], [587920.0, 0.0], [129170.0, 0.0], [620690.0, 0.0], [1144980.0, 0.0], [2128020.0, 0.0], [719000.0, 0.0], [751770.0, 0.0], [1734810.0, 0.0], [2062490.0, 0.0], [2259100.0, 0.0], [1374370.0, 0.0], [424100.0, 0.0], [2128040.0, 0.0], [358570.0, 0.0], [555180.0, 0.0], [719020.0, 0.0], [2521260.0, 0.0], [948400.0, 0.0], [2259120.0, 0.0], [2488500.0, 0.0], [2390200.0, 0.0], [1767610.0, 0.0], [653500.0, 0.0], [2783420.0, 0.0], [358590.0, 0.0], [63680.0, 0.0], [882880.0, 0.0], [424130.0, 0.0], [1571010.0, 0.0], [293060.0, 0.0], [1603780.0, 0.0], [1734860.0, 0.0], [948430.0, 0.0], [2422990.0, 0.0], [1079510.0, 0.0], [1112280.0, 0.0], [1603810.0, 0.0], [489700.0, 0.0], [1800420.0, 0.0], [2783460.0, 0.0], [358650.0, 0.0], [424190.0, 0.0], [2095360.0, 0.0], [1505540.0, 0.0], [1341710.0, 0.0], [2586900.0, 0.0], [2750740.0, 0.0], [489750.0, 0.0], [31000.0, 0.0], [1210650.0, 0.0], [2750750.0, 0.0], [1210660.0, 0.0], [1931560.0, 0.0], [915760.0, 0.0], [1079600.0, 0.0], [457010.0, 0.0], [948530.0, 0.0], [1276210.0, 0.0], [2423090.0, 0.0], [2718000.0, 0.0], [2390330.0, 0.0], [2423100.0, 0.0], [522560.0, 0.0], [784710.0, 0.0], [1276230.0, 0.0], [2783560.0, 0.0], [1505610.0, 0.0], [96600.0, 0.0], [424280.0, 0.0], [1112410.0, 0.0], [1603930.0, 0.0], [2160990.0, 0.0], [325990.0, 0.0], [2161000.0, 0.0], [194930.0, 0.0], [2095480.0, 0.0], [1964410.0, 0.0], [1702270.0, 0.0], [2062720.0, 0.0], [2423170.0, 0.009300019055198505], [653700.0, 0.0], [1505670.0, 0.0], [227730.0, 0.0], [1702290.0, 0.0], [2423190.0, 0.0], [2750870.0, 0.0], [162200.0, 0.0], [1636760.0, 0.0], [850330.0, 0.0], [2652570.0, 0.0], [1898910.0, 0.0], [391590.0, 0.2882097366902625], [1079720.0, 0.0], [1440170.0, 0.0], [1604010.0, 0.0], [1767850.0, 0.0], [1735090.0, 0.0], [2259380.0, 0.0], [2324920.0, 0.0], [1210810.0, 0.0], [424390.0, 0.0], [1571270.0, 0.0], [1735110.0, 0.0], [1309130.0, 0.0], [1014220.0, 0.0], [1210830.0, 0.0], [2193870.0, 0.0], [195030.0, 0.0], [227800.0, 0.0], [555480.0, 0.0], [260570.0, 0.0], [2685400.0, 0.0], [1767900.0, 0.0], [489950.0, 0.0], [1636830.0, 0.0], [2128350.0, 0.0], [129510.0, 0.0], [2456040.0, 0.0], [555500.0, 0.0], [1243630.0, 0.0], [1866230.0, 0.0], [653820.0, 0.0], [850430.0, 0.0], [1833470.0, 0.0], [883200.0, 0.0], [2685440.0, 0.0], [1735170.0, 0.0], [162310.0, 0.0], [64010.0, 0.0], [1047050.0, 0.0], [2226700.0, 0.0], [2095630.0, 0.0], [1964570.0, 0.0], [1112610.0, 0.0], [2587170.0, 0.0], [1636900.0, 0.0], [653870.0, 0.0], [817710.0, 0.0], [1473070.0, 0.0], [1210930.0, 0.0], [424500.0, 0.0], [784960.0, 0.0], [1276480.0, 0.0], [162370.0, 0.0], [555590.0, 0.0], [2619980.0, 0.0], [1505870.0, 0.0], [1374800.0, 0.0], [1702480.0, 0.0], [2226770.0, 0.0], [981590.0, 0.0], [2128470.0, 0.0], [2652760.0, 0.0], [1538650.0, 0.0], [2030170.0, 0.39477007685158866], [260700.0, 0.0], [1145440.0, 0.0], [2456160.0, 0.0], [555620.0, 0.0], [883300.0, 0.0], [2128490.0, 0.0], [1964660.0, -0.07783418303566465], [2718330.0, 0.0], [1440380.0, 0.0], [326270.0, 0.0], [424580.0, 0.0], [1243780.0, 0.0], [2751110.0, 0.0], [162440.0, 0.0], [2652810.0, 0.0], [1407630.0, 0.0], [2390670.0, 0.0], [2128530.0, 0.0], [195220.0, 0.0], [1702550.0, 0.0], [2063000.0, 0.0], [162460.0, 0.0], [2783900.0, 0.0], [1702560.0, 0.0], [2390700.0, 0.0], [359090.0, 0.0], [522930.0, 0.0], [2489010.0, 0.0], [654010.0, 0.0], [359100.0, 0.0], [2226880.0, 0.0], [817860.0, 0.0], [2063050.0, 0.0], [1964750.0, 0.0], [2128590.0, 0.0], [2292430.0, 0.0], [424660.0, 0.0], [2063060.0, 0.0], [2390740.0, 0.0], [31450.0, 0.0], [260840.0, 0.0], [2718440.0, 0.0], [2259690.0, 0.0], [1702640.0, 0.0], [1080050.0, 0.0], [1407730.0, 0.0], [1604340.0, 0.0], [228090.0, 0.0], [1374970.0, 0.0], [2030330.0, 0.0], [588550.0, 0.0], [326410.0, 0.0], [654090.0, 0.0], [359180.0, 0.0], [391950.0, 0.0], [621330.0, 0.0], [2194200.0, 0.0], [129820.0, 0.0], [785180.0, 0.0], [1112860.0, 0.0], [1145630.0, 0.0], [228130.0, 0.0], [1342250.0, 0.0], [916270.0, 0.0], [1571630.0, 0.0], [1145650.0, 0.0], [359220.0, 0.0], [64310.0, 0.0], [1211190.0, 0.0], [588600.0, 0.0], [2423610.0, 0.0], [1309500.0, 0.0], [64320.0, 0.0], [162630.0, 0.0], [2292550.0, 0.0], [2653000.0, 0.0], [1309520.0, 0.0], [359250.0, 0.0], [228180.0, 0.0], [916310.0, 0.0], [359260.0, 0.0], [2685790.0, 0.0], [2161510.0, 0.0], [2030440.0, 0.0], [916330.0, 0.0], [129900.0, 0.0], [1440620.0, 0.0], [424820.0, 0.0], [916340.0, 0.0], [752510.0, 0.0], [1964930.0, 0.0], [2456450.0, 0.0], [2489220.0, 0.0], [359310.0, 0.0], [1866640.0, 0.0], [2259860.0, 0.0], [687000.0, 0.0], [1178520.0, 0.0], [1375130.0, 0.0], [1997720.0, 0.0], [97180.0, 0.0], [1604510.0, 0.0], [2325410.0, 0.0], [1211300.0, 0.0], [1309610.0, 0.0], [2456490.0, 0.0], [457650.0, 0.0], [2259890.0, 0.0], [2456500.0, 0.0], [2784180.0, 0.0], [31670.0, 0.0], [621500.0, 0.0], [1768380.0, 0.0], [1342400.0, 0.0], [621510.0, 0.0], [2653130.0, 0.0], [228300.0, 0.0], [1145810.0, 0.0], [1178580.0, 0.0], [1211350.0, 0.0], [2227160.0, 0.0], [1965020.0, 0.0], [1014750.0, 0.0], [1506270.0, 0.0], [588770.0, 0.0], [1145830.0, 0.0], [2456550.0, 0.0], [2685930.0, 0.0], [949230.0, 0.0], [1801200.0, 0.0], [2128880.0, 0.0], [850930.0, 0.0], [2620400.0, 0.0], [1211380.0, 0.0], [2030580.0, 0.0], [916470.0, 0.0], [2063350.0, 0.0], [2259960.0, 0.0], [392190.0, 0.0], [2522110.0, 0.0], [1342470.0, 0.0], [2554890.0, 0.0], [2456600.0, 0.0], [1571870.0, 0.0], [556070.0, 0.0], [1047590.0, 0.0], [785450.0, 0.0], [2554930.0, 0.0], [293940.0, 0.0], [457780.0, 0.0], [2751540.0, 0.0], [949310.0, 0.0], [1637440.0, 0.0], [392270.0, 0.0], [2686030.0, 0.0], [261200.0, 0.0], [1309780.0, 0.0], [359510.0, 0.0], [2260060.0, 0.0], [2620510.0, 0.0], [654440.0, 0.0], [359530.0, 0.0], [687210.0, 0.0], [1178730.0, 0.0], [2522220.0, 0.0], [490610.0, 0.0], [1145970.0, 0.0], [195700.0, 0.0], [261240.0, 0.0], [785530.0, 0.0], [2096250.0, 0.0], [326780.0, 0.0], [2587770.0, 0.0], [195710.0, 0.0], [1997950.0, 0.0], [195730.0, 0.0], [2358420.0, 0.0], [621720.0, 0.0], [1146010.0, 0.0], [1375390.0, 0.0], [2030750.0, 0.0], [1637540.0, 0.0], [2227370.0, 0.0], [31920.0, 0.0], [1342640.0, 0.0], [720050.0, 0.0], [883890.0, 0.0], [1998000.0, 0.0], [2522290.0, 0.0], [2096310.0, 0.0], [687290.0, 0.0], [97470.0, 0.0], [294080.0, 0.0], [949440.0, 0.0], [1932480.0, 0.0], [1539270.0, 0.0], [1899730.0, 0.0], [1637590.0, 0.0], [1965270.0, 0.0], [2161880.0, 0.0], [1866970.0, 0.0], [2522330.0, 0.0], [261340.0, 0.0], [752860.0, 0.0], [2686180.0, 0.0], [2227430.0, 0.0], [785640.0, 0.0], [1637610.0, 0.0], [359660.0, 0.0], [523500.0, 0.0], [1670380.0, 0.0], [1408240.0, 0.0], [1801460.0, 0.0], [621820.0, 0.0], [1146110.0, 0.0], [1703170.0, 0.0], [949510.0, 0.0], [2751750.0, 0.0], [1015050.0, 0.0], [1506570.0, 0.0], [1211660.0, 0.0], [2686220.0, 0.26179166634189327], [949520.0, 0.0], [818450.0, 0.0], [556310.0, 0.0], [1211670.0, 0.0], [1703190.0, 0.0], [2424090.0, 0.0], [326940.0, 0.0], [982300.0, 0.0], [2325790.0, 0.0], [2260260.0, 0.0], [294190.0, 0.0], [1441070.0, 0.0], [818480.0, 0.0], [1768750.0, 0.0], [1506610.0, 0.0], [2489650.0, 0.0], [1211700.0, 0.0], [2587950.0, 0.0], [589110.0, 0.0], [1473850.0, 0.0], [1342780.0, 0.0], [785730.0, 0.0], [1506630.0, 0.0], [2325830.0, 0.0], [261450.0, 0.0], [2129230.0, 0.0], [1768790.0, 0.0], [1146200.0, 0.0], [1015130.0, 0.0], [294240.0, 0.0], [621930.0, 0.0], [818540.0, 0.0], [359790.0, 0.0], [1211760.0, 0.0], [916850.0, 0.0], [1113460.0, 0.0], [1441140.0, 0.0], [818550.0, 0.0], [851320.0, 0.0], [1670520.0, 0.0], [1637760.0, 0.0], [1015170.0, 0.0], [1211780.0, 0.0], [2063750.0, 0.0], [2293130.0, 0.0], [949650.0, 0.0], [64920.0, 0.0], [720280.0, 0.0], [261530.0, 0.0], [884120.0, 0.0], [1047960.0, 0.0], [1670560.0, 0.0], [753060.0, 0.0], [1768870.0, 0.0], [1473960.0, 0.0], [1539500.0, 0.0], [2391470.0, 0.0], [1146290.0, 0.0], [2686390.0, 0.0], [916920.0, 0.0], [2162110.0, 0.0], [884160.0, 0.0], [1211840.0, 0.0], [2457030.0, 0.0], [228810.0, 0.0], [949710.0, 0.0], [1605070.0, 0.0], [196050.0, 0.0], [818650.0, 0.0], [1342940.0, 0.0], [785890.0, 0.0], [1605090.0, 0.0], [1146340.0, 0.0], [687600.0, 0.0], [65010.0, 0.0], [1441270.0, 0.0], [1605110.0, 0.0], [654840.0, 0.0], [1474040.0, 0.0], [1310210.0, 0.0], [556550.0, 0.0], [228880.0, 0.0], [949780.0, 0.0], [1113620.0, 0.0], [654870.0, 0.0], [359960.0, 0.0], [65050.0, 0.0], [327210.0, 0.0], [2293290.0, 0.0], [359980.0, 0.0], [2555440.0, 0.0], [1310260.0, 0.0], [687670.0, 0.0], [1048120.0, 0.0], [2358840.0, 0.0], [2063930.0, 0.0], [2391610.0, 0.0], [1441340.0, 0.0], [1769020.0, 0.0], [1146430.0, 0.0], [1310270.0, 0.0], [687680.0, 0.0], [2293310.0, 0.0], [1244740.0, 0.0], [2555460.0, 0.0], [1769030.0, 0.0], [1637960.0, 0.0], [491090.0, 0.0], [949850.0, -0.12410127857176076], [1474140.0, 0.0], [2293340.0, 0.0], [360030.0, 0.0], [2326110.0, 0.0], [1375840.0, 0.0], [2358880.0, 0.0], [2752100.0, 0.0], [982630.0, 0.0], [392810.0, 0.0], [2686570.0, 0.0], [1277550.0, 0.0], [1310320.0, 0.0], [1179250.0, 0.0], [1572470.0, 0.0], [654970.0, 0.0], [884350.0, 0.0], [1375870.0, 0.0], [1343110.0, 0.0], [2653830.0, 0.0], [229000.0, 0.0], [392840.0, 0.0], [1375880.0, 0.0], [1932940.0, 0.0], [1212050.0, 0.0], [1375890.0, 0.0], [753300.0, 0.0], [1474200.0, 0.0], [1638040.0, 0.0], [851610.0, 0.0], [1015460.0, 0.0], [2358950.0, 0.0], [2522790.0, 0.0], [1572520.0, 0.0], [2227880.0, 0.0], [1146550.0, 0.0], [2686650.0, 0.0], [261820.0, 0.0], [2293440.0, 0.0], [2522820.0, 0.0], [1244870.0, 0.0], [1769160.0, 0.0], [2096840.0, 0.0], [2752200.0, 0.0], [1081040.0, 0.0], [1244880.0, 0.0], [949970.0, 0.0], [2260690.0, 0.0], [1244890.0, 0.0], [1507040.0, 0.0], [1441510.0, 0.0], [1998570.0, 0.0], [130800.0, 0.0], [2129650.0, 0.0], [2522870.0, 0.0], [786170.0, 0.0], [1146620.0, 0.0], [1310460.0, 0.0], [2621180.0, 0.0], [229120.0, 0.0], [1703680.0, 0.0], [425730.0, 0.0], [130820.0, 0.0], [2424580.0, 0.0], [1834760.0, 0.0], [1376010.0, 0.0], [261900.0, 0.0], [1408790.0, 0.0], [2752280.0, 0.0], [1605410.0, 0.0], [65320.0, 0.0], [1703720.0, 0.0], [589610.0, 0.0], [1900330.0, 0.0], [1113900.0, 0.0], [2522920.0, 0.0], [1736500.0, 0.0], [622390.0, 0.0], [2457400.0, 0.0], [261960.0, 0.0], [589640.0, 0.0], [2654030.0, 0.0], [950100.0, 0.0], [1441620.0, 0.0], [65370.0, 0.0], [1277790.0, 0.0], [950110.0, 0.0], [1867620.0, 0.0], [2195300.0, 0.0], [2064230.0, 0.0], [1605480.0, 0.0], [1310570.0, 0.0], [1015660.0, 0.0], [130930.0, 0.0], [1998710.0, 0.0], [1572730.0, 0.0], [130940.0, 0.0], [1277820.0, 0.0], [1605510.0, 0.0], [65430.0, 0.0], [1965980.0, 0.0], [2457500.0, 0.0], [2162600.0, 0.0], [1408940.0, 0.0], [2555820.0, 0.0], [982970.0, 0.0], [1540030.0, 0.0], [2686910.0, 0.0], [2424770.0, 0.0], [2129860.0, 0.0], [2785220.0, 0.0], [720840.0, 0.0], [1376200.0, 0.0], [1572810.0, 0.0], [2031560.0, 0.0], [1605580.0, 0.0], [2686920.0, 0.0], [1474510.0, 0.0], [1081300.0, 0.0], [524250.0, 0.0], [2228190.0, 0.0], [131040.0, 0.0], [950250.0, 0.0], [1343470.0, 0.0], [1179630.0, 0.0], [196590.0, 0.0], [229360.0, 0.0], [360430.0, 0.0], [425970.0, 0.0], [688110.0, 0.0], [163830.0, 0.0], [2031610.0, 0.0], [2064380.0, 0.0], [1277950.0, 0.0]]\n"
    }
   ],
   "source": [
    "user = list(test_dict.keys())[0]    \n",
    "print('user:{}'.format(user))\n",
    "\n",
    "#clique = compute_clique_without_implicit(user, train_dict, 100) without implicit\n",
    "\n",
    "clique = compute_clique_with_implicit(user, train_dict_explicit, train_dict_implicit, 100, 1, 1) #TODO define a and b in a proper manner\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[3.12252617e+09 8.19595672e+00 8.00000000e+00]\n [3.12261594e+09 7.98326267e+00 8.00000000e+00]\n [4.46677450e+09 9.30793171e+00 1.00000000e+01]\n [4.51166892e+09 6.16150924e+00 3.00000000e+00]]\n"
    }
   ],
   "source": [
    "test_items = list(test_dict[user].keys())\n",
    "\n",
    "#predictions = np.array([ [item, predict(user, item, clique, train_dict), test_dict[user][item]] for item in test_items])\n",
    "predictions = np.array([ [item, predict(user, item, clique, train_dict_explicit), test_dict[user][item]] for item in test_items])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bitcc8835991869480f89c8170dbe69b2e5",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}