{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys \n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_path = os.path.join(os.path.join(os.getcwd(),'Datasets'),'movies_dataset')\n",
    "\n",
    "metadata_path = os.path.join(movies_path,'movies_metadata.csv')\n",
    "movies_genre_path = os.path.join(movies_path, 'movies.csv')\n",
    "ratings_path = os.path.join(movies_path,'ratings.csv')\n",
    "links_path = os.path.join(movies_path,'links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "metadata loaded\nratings loaded\ngenre loaded\ngenre loaded\n"
    }
   ],
   "source": [
    "metadata = pd.read_csv(metadata_path)\n",
    "print('metadata loaded')\n",
    "ratings = pd.read_csv(ratings_path)\n",
    "ratings = ratings.drop(columns='timestamp')\n",
    "print('ratings loaded')\n",
    "genres = pd.read_csv(movies_genre_path)\n",
    "print('genre loaded')\n",
    "links = pd.read_csv(links_path)\n",
    "print('genre loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = metadata.drop(columns = ['adult', 'belongs_to_collection', 'budget', 'homepage', 'overview',\n",
    "       'popularity', 'poster_path','release_date', 'original_title','revenue', 'runtime', 'status', 'tagline', 'video','vote_average', 'vote_count'])\n",
    "\n",
    "metadata = metadata[metadata.id != '1997-08-20']\n",
    "metadata = metadata[metadata.id != '2012-09-29']\n",
    "metadata = metadata[metadata.id != '2014-01-01']\n",
    "metadata = metadata.astype({'id':'float64'})\n",
    "\n",
    "links.astype({'tmdbId':'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>movieId</th>\n      <th>imdbId</th>\n      <th>tmdbId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>114709</td>\n      <td>862.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>113497</td>\n      <td>8844.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>113228</td>\n      <td>15602.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>114885</td>\n      <td>31357.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>113041</td>\n      <td>11862.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>58093</th>\n      <td>193876</td>\n      <td>38566</td>\n      <td>78251.0</td>\n    </tr>\n    <tr>\n      <th>58094</th>\n      <td>193878</td>\n      <td>1754787</td>\n      <td>87558.0</td>\n    </tr>\n    <tr>\n      <th>58095</th>\n      <td>193880</td>\n      <td>5847740</td>\n      <td>422666.0</td>\n    </tr>\n    <tr>\n      <th>58096</th>\n      <td>193882</td>\n      <td>4453756</td>\n      <td>454439.0</td>\n    </tr>\n    <tr>\n      <th>58097</th>\n      <td>193886</td>\n      <td>7606620</td>\n      <td>540871.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>58098 rows × 3 columns</p>\n</div>",
      "text/plain": "       movieId   imdbId    tmdbId\n0            1   114709     862.0\n1            2   113497    8844.0\n2            3   113228   15602.0\n3            4   114885   31357.0\n4            5   113041   11862.0\n...        ...      ...       ...\n58093   193876    38566   78251.0\n58094   193878  1754787   87558.0\n58095   193880  5847740  422666.0\n58096   193882  4453756  454439.0\n58097   193886  7606620  540871.0\n\n[58098 rows x 3 columns]"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>genres</th>\n      <th>original_language</th>\n      <th>production_companies</th>\n      <th>production_countries</th>\n      <th>spoken_languages</th>\n      <th>title</th>\n      <th>movieId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n      <td>en</td>\n      <td>[{'name': 'Pixar Animation Studios', 'id': 3}]</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Toy Story</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n      <td>en</td>\n      <td>[{'name': 'TriStar Pictures', 'id': 559}, {'na...</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n      <td>Jumanji</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n      <td>en</td>\n      <td>[{'name': 'Warner Bros.', 'id': 6194}, {'name'...</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Grumpier Old Men</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n      <td>en</td>\n      <td>[{'name': 'Twentieth Century Fox Film Corporat...</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Waiting to Exhale</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n      <td>en</td>\n      <td>[{'name': 'Sandollar Productions', 'id': 5842}...</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Father of the Bride Part II</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>45507</th>\n      <td>[{'id': 18, 'name': 'Drama'}, {'id': 10751, 'n...</td>\n      <td>fa</td>\n      <td>[]</td>\n      <td>[{'iso_3166_1': 'IR', 'name': 'Iran'}]</td>\n      <td>[{'iso_639_1': 'fa', 'name': 'فارسی'}]</td>\n      <td>Subdue</td>\n      <td>176269</td>\n    </tr>\n    <tr>\n      <th>45508</th>\n      <td>[{'id': 18, 'name': 'Drama'}]</td>\n      <td>tl</td>\n      <td>[{'name': 'Sine Olivia', 'id': 19653}]</td>\n      <td>[{'iso_3166_1': 'PH', 'name': 'Philippines'}]</td>\n      <td>[{'iso_639_1': 'tl', 'name': ''}]</td>\n      <td>Century of Birthing</td>\n      <td>176271</td>\n    </tr>\n    <tr>\n      <th>45509</th>\n      <td>[{'id': 28, 'name': 'Action'}, {'id': 18, 'nam...</td>\n      <td>en</td>\n      <td>[{'name': 'American World Pictures', 'id': 6165}]</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Betrayal</td>\n      <td>176273</td>\n    </tr>\n    <tr>\n      <th>45510</th>\n      <td>[]</td>\n      <td>en</td>\n      <td>[{'name': 'Yermoliev', 'id': 88753}]</td>\n      <td>[{'iso_3166_1': 'RU', 'name': 'Russia'}]</td>\n      <td>[]</td>\n      <td>Satan Triumphant</td>\n      <td>176275</td>\n    </tr>\n    <tr>\n      <th>45511</th>\n      <td>[]</td>\n      <td>en</td>\n      <td>[]</td>\n      <td>[{'iso_3166_1': 'GB', 'name': 'United Kingdom'}]</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Queerama</td>\n      <td>176279</td>\n    </tr>\n  </tbody>\n</table>\n<p>45512 rows × 7 columns</p>\n</div>",
      "text/plain": "                                                  genres original_language  \\\n0      [{'id': 16, 'name': 'Animation'}, {'id': 35, '...                en   \n1      [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...                en   \n2      [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...                en   \n3      [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...                en   \n4                         [{'id': 35, 'name': 'Comedy'}]                en   \n...                                                  ...               ...   \n45507  [{'id': 18, 'name': 'Drama'}, {'id': 10751, 'n...                fa   \n45508                      [{'id': 18, 'name': 'Drama'}]                tl   \n45509  [{'id': 28, 'name': 'Action'}, {'id': 18, 'nam...                en   \n45510                                                 []                en   \n45511                                                 []                en   \n\n                                    production_companies  \\\n0         [{'name': 'Pixar Animation Studios', 'id': 3}]   \n1      [{'name': 'TriStar Pictures', 'id': 559}, {'na...   \n2      [{'name': 'Warner Bros.', 'id': 6194}, {'name'...   \n3      [{'name': 'Twentieth Century Fox Film Corporat...   \n4      [{'name': 'Sandollar Productions', 'id': 5842}...   \n...                                                  ...   \n45507                                                 []   \n45508             [{'name': 'Sine Olivia', 'id': 19653}]   \n45509  [{'name': 'American World Pictures', 'id': 6165}]   \n45510               [{'name': 'Yermoliev', 'id': 88753}]   \n45511                                                 []   \n\n                                    production_countries  \\\n0      [{'iso_3166_1': 'US', 'name': 'United States o...   \n1      [{'iso_3166_1': 'US', 'name': 'United States o...   \n2      [{'iso_3166_1': 'US', 'name': 'United States o...   \n3      [{'iso_3166_1': 'US', 'name': 'United States o...   \n4      [{'iso_3166_1': 'US', 'name': 'United States o...   \n...                                                  ...   \n45507             [{'iso_3166_1': 'IR', 'name': 'Iran'}]   \n45508      [{'iso_3166_1': 'PH', 'name': 'Philippines'}]   \n45509  [{'iso_3166_1': 'US', 'name': 'United States o...   \n45510           [{'iso_3166_1': 'RU', 'name': 'Russia'}]   \n45511   [{'iso_3166_1': 'GB', 'name': 'United Kingdom'}]   \n\n                                        spoken_languages  \\\n0               [{'iso_639_1': 'en', 'name': 'English'}]   \n1      [{'iso_639_1': 'en', 'name': 'English'}, {'iso...   \n2               [{'iso_639_1': 'en', 'name': 'English'}]   \n3               [{'iso_639_1': 'en', 'name': 'English'}]   \n4               [{'iso_639_1': 'en', 'name': 'English'}]   \n...                                                  ...   \n45507             [{'iso_639_1': 'fa', 'name': 'فارسی'}]   \n45508                  [{'iso_639_1': 'tl', 'name': ''}]   \n45509           [{'iso_639_1': 'en', 'name': 'English'}]   \n45510                                                 []   \n45511           [{'iso_639_1': 'en', 'name': 'English'}]   \n\n                             title  movieId  \n0                        Toy Story        1  \n1                          Jumanji        2  \n2                 Grumpier Old Men        3  \n3                Waiting to Exhale        4  \n4      Father of the Bride Part II        5  \n...                            ...      ...  \n45507                       Subdue   176269  \n45508          Century of Birthing   176271  \n45509                     Betrayal   176273  \n45510             Satan Triumphant   176275  \n45511                     Queerama   176279  \n\n[45512 rows x 7 columns]"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "merged = pd.merge(metadata, links, left_on=['id'], right_on=['tmdbId']).drop(columns=['id','imdb_id','imdbId','tmdbId'])\n",
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "------------------------------------------------------------\nTraceback (most recent call last):\n  File \"<ipython-input-51-e7e2ac94a4ce>\", line 43, in <module>\n    prod_comp_row = eval(metadata.iloc[index,:].production_companies)\nTypeError: eval() arg 1 must be a string, bytes or code object\n------------------------------------------------------------\n------------------------------------------------------------\nTraceback (most recent call last):\n  File \"<ipython-input-51-e7e2ac94a4ce>\", line 43, in <module>\n    prod_comp_row = eval(metadata.iloc[index,:].production_companies)\nTypeError: eval() arg 1 must be a string, bytes or code object\n------------------------------------------------------------\n------------------------------------------------------------\nTraceback (most recent call last):\n  File \"<ipython-input-51-e7e2ac94a4ce>\", line 43, in <module>\n    prod_comp_row = eval(metadata.iloc[index,:].production_companies)\nTypeError: eval() arg 1 must be a string, bytes or code object\n------------------------------------------------------------\n"
    }
   ],
   "source": [
    "metadata = merged\n",
    "nrows = metadata.shape[0]\n",
    "\n",
    "movies = {}\n",
    "for index in range(nrows):\n",
    "\n",
    "    # get the id of the movie\n",
    "    try:\n",
    "        id_row = int(metadata.iloc[index,:].movieId)\n",
    "    except:\n",
    "        print('-'*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print('-'*60)\n",
    "        continue\n",
    "\n",
    "\n",
    "    # get the genres of the movie\n",
    "    try:\n",
    "         genres_row = eval(metadata.iloc[index,:].genres)\n",
    "         genres_list = []\n",
    "         for genres_dict in genres_row:\n",
    "            id_ = genres_dict['id']\n",
    "            genres_list.append(id_)\n",
    "    except:\n",
    "        print('-'*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print('-'*60)\n",
    "        continue\n",
    "\n",
    "    # get original language\n",
    "    try:\n",
    "         original_row = metadata.iloc[index,:].original_language\n",
    "    except:\n",
    "        print('-'*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print('-'*60)\n",
    "        continue\n",
    "\n",
    "    \n",
    "    # get the production companies\n",
    "    try:\n",
    "        prod_comp_list = []\n",
    "        prod_comp_row = eval(metadata.iloc[index,:].production_companies)\n",
    "        for prod_comp_dict in prod_comp_row:\n",
    "            id_ = prod_comp_dict['id']\n",
    "            prod_comp_list.append(id_)\n",
    "    except:\n",
    "        print('-'*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print('-'*60)\n",
    "        continue\n",
    "\n",
    "    # get the production countries\n",
    "    try:\n",
    "        prod_countries_list = []\n",
    "        prod_countries_row = eval(metadata.iloc[index,:].production_countries)\n",
    "        for prod_countries_dict in prod_countries_row:\n",
    "            country = prod_countries_dict['iso_3166_1']\n",
    "            prod_countries_list.append(country)\n",
    "    except:\n",
    "        print('-'*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print('-'*60)\n",
    "        continue\n",
    "\n",
    "    # get the production countries\n",
    "    try:\n",
    "        spoken_languages_list = []\n",
    "        spoken_languages_row = eval(metadata.iloc[index,:].spoken_languages)\n",
    "        for spoken_languages_dict in spoken_languages_row:\n",
    "            spoken_language = spoken_languages_dict['iso_639_1']\n",
    "            spoken_languages_list.append(spoken_language)\n",
    "    except:\n",
    "        print('-'*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print('-'*60)\n",
    "        continue\n",
    "\n",
    "    movies[id_row] = {'genres':genres_list,\n",
    "                    'original_language':original_row,\n",
    "                    'production_companies':prod_comp_list,\n",
    "                    'production_countries': prod_countries_list,\n",
    "                    'spoken_language':spoken_languages_list}\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "45447"
     },
     "metadata": {},
     "execution_count": 52
    }
   ],
   "source": [
    "len(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./movies_metadata.txt','w') as fw:\n",
    "    json.dump(movies, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "45430\n"
    }
   ],
   "source": [
    "with  open('./movies_metadata.txt','r') as fr:\n",
    "    data = json.load(fr)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_users(ratings):\n",
    "    # count occurrences of same userId\n",
    "    print(ratings.shape)\n",
    "    ids = ratings.userId\n",
    "    counts = ids.value_counts()\n",
    "\n",
    "    # select ids to keep (users with #ratings >= 5)\n",
    "    to_keep = counts[counts.values >= 50].index\n",
    "    mask = [(x in to_keep) for x in ratings.userId]\n",
    "    ratings_5 = ratings[mask]\n",
    "    return ratings_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_movies(ratings):\n",
    "    # count occurrences of same movieId\n",
    "    print(ratings.shape)\n",
    "    ids = ratings.movieId\n",
    "    counts = ids.value_counts()\n",
    "\n",
    "    # select ids to keep (movies with #ratings >= 20)\n",
    "    to_keep = counts[counts.values >= 50].index\n",
    "    mask = [(x in to_keep) for x in ratings.movieId]\n",
    "    ratings_20 = ratings[mask]\n",
    "    return ratings_20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter(ratings):\n",
    "    num_rows = ratings.shape[0]\n",
    "\n",
    "    tmp = ratings\n",
    "    while True:\n",
    "        tmp_5 = filter_users(tmp)\n",
    "        if tmp_5.shape[0] == tmp.shape[0]:\n",
    "            print('convergence has been reached')\n",
    "            print('users now are {}'.format(len(tmp_5.userId.unique())))\n",
    "            print('movies are now {}'.format(len(tmp_20.movieId.unique())))\n",
    "            return tmp_5\n",
    "        else:\n",
    "            print('users filtered')\n",
    "            print('users now are {}'.format(len(tmp_5.userId.unique())))\n",
    "            tmp = tmp_5\n",
    "        tmp_20 = filter_movies(tmp)\n",
    "        if tmp_20.shape[0] == tmp.shape[0]:\n",
    "            print('convergence has been reached')\n",
    "            print('users now are {}'.format(len(tmp_5.userId.unique())))\n",
    "            print('movies are now {}'.format(len(tmp_20.movieId.unique())))\n",
    "            return tmp_20\n",
    "        else:\n",
    "            print('movies filtered')\n",
    "            print('movies are now {}'.format(len(tmp_20.movieId.unique())))\n",
    "            tmp = tmp_20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(26024289, 3)\nusers filtered\nusers now are 103839\n(22879277, 3)\nmovies filtered\nmovies are now 12341\n(22610090, 3)\nusers filtered\nusers now are 103652\n(22601367, 3)\nmovies filtered\nmovies are now 12333\n(22600977, 3)\nusers filtered\nusers now are 103651\n(22600928, 3)\nconvergence has been reached\nusers now are 103651\nmovies are now 12333\n"
    }
   ],
   "source": [
    "final_ratings = filter(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "12333"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "len(final_ratings.movieId.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_user_based_dictionary(unique_users, ratings):\n",
    "    print('\\nunique users in this batch are from {} to {}'.format(unique_users[0], unique_users[-1]))\n",
    "    print('\\nthe shape of ratings is {}'.format(ratings.shape))\n",
    "    sparse_user_based = {}\n",
    "\n",
    "    for user in unique_users:\n",
    "        user_ratings = {}\n",
    "        user_subtable = ratings[ratings.userId == user]\n",
    "        for index,row in user_subtable.iterrows():\n",
    "            user_ratings[str(row['movieId'])] = str(row['rating'])\n",
    "        sparse_user_based[str(user)] = user_ratings\n",
    "        if user%1000 in [0,1]:\n",
    "            print('user is {}'.format(user))\n",
    "    return sparse_user_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_item_based_dictionary(unique_movies, ratings):\n",
    "    print('\\nunique movies in this batch are from {} to {}'.format(unique_movies[0], unique_movies[-1]))\n",
    "    print('\\nthe shape of ratings is {}'.format(ratings.shape))\n",
    "    sparse_item_based = {}\n",
    "\n",
    "    for movie in unique_movies:\n",
    "        movie_ratings = {}\n",
    "        movie_subtable = ratings[ratings.movieId == movie]\n",
    "        for index,row in movie_subtable.iterrows():\n",
    "            movie_ratings[str(row['userId'])] = str(row['rating'])\n",
    "        sparse_item_based[str(movie)] = movie_ratings\n",
    "        if movie%500 in [0,1]:\n",
    "            print('movie is {}'.format(movie))\n",
    "    return sparse_item_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class CreateUtilityThread(Thread):\n",
    "    def __init__(self, name = None, unique_users = None, unique_items = None, ratings = None, job = None):\n",
    "        Thread.__init__(self)\n",
    "        self.name = name\n",
    "        self.unique_users = unique_users\n",
    "        self.unique_items = unique_items\n",
    "        self.ratings = ratings\n",
    "        self.job = job\n",
    "        self._return = None\n",
    "\n",
    "    def run(self):\n",
    "        print(self.name)\n",
    "        if self.name is not None:\n",
    "            if self.job == 'item_based':\n",
    "                self._return = build_item_based_dictionary(self.unique_items, self.ratings)\n",
    "            elif self.job == 'user_based':\n",
    "                self._return = build_user_based_dictionary(self.unique_users, self.ratings)\n",
    "            else:\n",
    "                print('Error, you have to specify a job')\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        if self._return is not None:\n",
    "            return self._return\n",
    "        else:\n",
    "            print('Error using threading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(l):\n",
    "    n = len(l) // 2          # length of smaller half\n",
    "    \n",
    "    l1 = l[:n]\n",
    "    l2 = l[n:]\n",
    "\n",
    "    return l1, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "thread-1thread-2\n\nunique users in this batch are from 34010 to 67769\n\nthe shape of ratings is (25709727, 3)\n\n\nunique users in this batch are from 1 to 34009\n\nthe shape of ratings is (25709727, 3)thread-3\n\n\nunique users in this batch are from 67770 to 101724\n\nthe shape of ratings is (25709727, 3)\nthread-4\n\nunique users in this batch are from 101725 to 135636\n\nthe shape of ratings is (25709727, 3)\nthread-5\n\nunique users in this batch are from 135637 to 169389\n\nthe shape of ratings is (25709727, 3)\nthread-6thread-7\n\nunique users in this batch are from 203208 to 236978\n\nthe shape of ratings is (25709727, 3)\n\n\nunique users in this batch are from 169394 to 203207\n\nthe shape of ratings is (25709727, 3)\nthread-8============= all threads started =============\n\n\nunique users in this batch are from 236979 to 270896\n\nthe shape of ratings is (25709727, 3)\nuser is 1\nuser is 237000\nuser is 237001\nuser is 68000\nuser is 68001\nuser is 102000\nuser is 102001\nuser is 136000\nuser is 136001\nuser is 170001\nuser is 204000\nuser is 204001\nuser is 35000\nuser is 35001\nuser is 1001\nuser is 238000\nuser is 238001\nuser is 69000\nuser is 69001\nuser is 103000\nuser is 103001\nuser is 137000\nuser is 137001\nuser is 171000\nuser is 171001\nuser is 205000\nuser is 205001\nuser is 36001\nuser is 2000\nuser is 2001\nuser is 239001\nuser is 70001\nuser is 104000\nuser is 104001\nuser is 138000\nuser is 138001\nuser is 172000\nuser is 172001\nuser is 206000\nuser is 3000\nuser is 3001\nuser is 37000\nuser is 37001\nuser is 71001\nuser is 105000\nuser is 139000\nuser is 139001\nuser is 173000\nuser is 173001\nuser is 207000\nuser is 207001\nuser is 4000\nuser is 4001\nuser is 38001\nuser is 241001\nuser is 106000\nuser is 106001\nuser is 72000\nuser is 140000\nuser is 140001\nuser is 174000\nuser is 174001\nuser is 208000\nuser is 208001\nuser is 5000\nuser is 5001\nuser is 39000\nuser is 39001\nuser is 242000\nuser is 242001\nuser is 73000\nuser is 73001\nuser is 107000\nuser is 107001\nuser is 141000\nuser is 141001\nuser is 175000\nuser is 175001\nuser is 209000\nuser is 209001\nuser is 40000\nuser is 40001\nuser is 243000\nuser is 243001\nuser is 74000\nuser is 74001\nuser is 108000\nuser is 108001\nuser is 142000\nuser is 142001\nuser is 176000\nuser is 176001\nuser is 210000\nuser is 210001\nuser is 41000\nuser is 7000\nuser is 7001\nuser is 244000\nuser is 244001\nuser is 75000\nuser is 75001\nuser is 109000\nuser is 109001\nuser is 143000\nuser is 143001\nuser is 177000\nuser is 211000\nuser is 211001\nuser is 42000\nuser is 42001\nuser is 8000\nuser is 8001\nuser is 245000\nuser is 245001\nuser is 76000\nuser is 76001\nuser is 110000\nuser is 110001\nuser is 144000\nuser is 144001\nuser is 178000\nuser is 178001\nuser is 212000\nuser is 212001\nuser is 9000\nuser is 43000\nuser is 43001\nuser is 246000\nuser is 246001\nuser is 77000\nuser is 77001\nuser is 111000\nuser is 111001\nuser is 145000\nuser is 145001\nuser is 179000\nuser is 213000\nuser is 213001\nuser is 10001\nuser is 44000\nuser is 44001\nuser is 247000\nuser is 247001\nuser is 78000\nuser is 78001\nuser is 112000\nuser is 112001\nuser is 146000\nuser is 146001\nuser is 180000\nuser is 180001\nuser is 214000\nuser is 214001\nuser is 11000\nuser is 11001\nuser is 248000\nuser is 45000\nuser is 45001\nuser is 113000\nuser is 113001\nuser is 79000\nuser is 79001\nuser is 147001\nuser is 181000\nuser is 181001\nuser is 215000\nuser is 12000\nuser is 12001\nuser is 249000\nuser is 46000\nuser is 46001\nuser is 114001\nuser is 80000\nuser is 80001\nuser is 148000\nuser is 148001\nuser is 182000\nuser is 182001\nuser is 216000\nuser is 216001\nuser is 13000\nuser is 13001\nuser is 250000\nuser is 250001\nuser is 47000\nuser is 47001\nuser is 115000\nuser is 115001\nuser is 81000\nuser is 81001\nuser is 149000\nuser is 183000\nuser is 183001\nuser is 217000\nuser is 217001\nuser is 14000\nuser is 14001\nuser is 251000\nuser is 251001\nuser is 48000\nuser is 48001\nuser is 116000\nuser is 116001\nuser is 82000\nuser is 82001\nuser is 150000\nuser is 150001\nuser is 184001\nuser is 218001\nuser is 15000\nuser is 252000\nuser is 252001\nuser is 49000\nuser is 49001\nuser is 117000\nuser is 117001\nuser is 83000\nuser is 83001\nuser is 151000\nuser is 185000\nuser is 185001\nuser is 219000\nuser is 16000\nuser is 16001\nuser is 253000\nuser is 50000\nuser is 50001\nuser is 118001\nuser is 84000\nuser is 152001\nuser is 186000\nuser is 186001\nuser is 220000\nuser is 220001\nuser is 17000\nuser is 17001\nuser is 254000\nuser is 254001\nuser is 51000\nuser is 51001\nuser is 153000\nuser is 153001\nuser is 187000\nuser is 187001\nuser is 221001\nuser is 18000\nuser is 18001\nuser is 255000\nuser is 255001\nuser is 52000\nuser is 52001\nuser is 120000\nuser is 120001\nuser is 86000\nuser is 86001\nuser is 154000\nuser is 154001\nuser is 188000\nuser is 188001\nuser is 222000\nuser is 222001\nuser is 19000\nuser is 19001\nuser is 256000\nuser is 256001\nuser is 53000\nuser is 121000\nuser is 121001\nuser is 87000\nuser is 87001\nuser is 155000\nuser is 155001\nuser is 189000\nuser is 189001\nuser is 223000\nuser is 223001\nuser is 20000\nuser is 257000\nuser is 257001\nuser is 54000\nuser is 54001\nuser is 122001\nuser is 88001\nuser is 156000\nuser is 190000\nuser is 190001\nuser is 224000\nuser is 21000\nuser is 21001\nuser is 258000\nuser is 258001\nuser is 55000\nuser is 55001\nuser is 123000\nuser is 123001\nuser is 89001\nuser is 157000\nuser is 157001\nuser is 191000\nuser is 191001\nuser is 225000\nuser is 225001\nuser is 22000\nuser is 22001\nuser is 259000\nuser is 259001\nuser is 56000\nuser is 56001\nuser is 124000\nuser is 124001\nuser is 158000\nuser is 90000\nuser is 158001\nuser is 90001\nuser is 192000\nuser is 192001\nuser is 226000\nuser is 226001\nuser is 260000\nuser is 23000\nuser is 23001\nuser is 57000\nuser is 57001\nuser is 125000\nuser is 125001\nuser is 159000\nuser is 159001\nuser is 91000\nuser is 91001\nuser is 193000\nuser is 193001\nuser is 227000\nuser is 227001\nuser is 24000\nuser is 24001\nuser is 261000\nuser is 261001\nuser is 58000\nuser is 58001\nuser is 126000\nuser is 126001\nuser is 92001\nuser is 160001\nuser is 194000\nuser is 228000\nuser is 228001\nuser is 25001\nuser is 262001\nuser is 59000\nuser is 59001\nuser is 93000\nuser is 161000\nuser is 161001\nuser is 195000\nuser is 195001\nuser is 263000\nuser is 263001\nuser is 26001\nuser is 229000\nuser is 229001\nuser is 60000\nuser is 60001\nuser is 128000\nuser is 128001\nuser is 94000\nuser is 94001\nuser is 162000\nuser is 162001\nuser is 196000\nuser is 196001\nuser is 27000\nuser is 27001\nuser is 264000\nuser is 230000\nuser is 230001\nuser is 61000\nuser is 61001\nuser is 129000\nuser is 129001\nuser is 95000\nuser is 95001\nuser is 163000\nuser is 163001\nuser is 197000\nuser is 197001\nuser is 265000\nuser is 265001\nuser is 231001\nuser is 28000\nuser is 28001\nuser is 62000\nuser is 62001\nuser is 130000\nuser is 130001\nuser is 96001\nuser is 164000\nuser is 164001\nuser is 198000\nuser is 198001\nuser is 266000\nuser is 232000\nuser is 29000\nuser is 232001\nuser is 29001\nuser is 63000\nuser is 63001\nuser is 131000\nuser is 97000\nuser is 165000\nuser is 165001\nuser is 199001\nuser is 267000\nuser is 267001\nuser is 30000\nuser is 30001\nuser is 233000\nuser is 233001\nuser is 64000\nuser is 64001\nuser is 132000\nuser is 132001\nuser is 98000\nuser is 98001\nuser is 166000\nuser is 166001\nuser is 200000\nuser is 200001\nuser is 234000\nuser is 234001\nuser is 268000\nuser is 268001\nuser is 31000\nuser is 31001\nuser is 65000\nuser is 133000\nuser is 133001\nuser is 99000\nuser is 99001\nuser is 167000\nuser is 167001\nuser is 201001\nuser is 235000\nuser is 235001\nuser is 32001\nuser is 269001\nuser is 66000\nuser is 66001\nuser is 134000\nuser is 100000\nuser is 100001\nuser is 168000\nuser is 168001\nuser is 202001\nuser is 236001\nuser is 33000\nuser is 33001\nuser is 270000\nuser is 270001\nuser is 67000\nuser is 67001\nuser is 135001\nuser is 101000\nuser is 101001\nuser is 169000\nuser is 203000\nuser is 203001\nuser is 34000\nuser is 34001\n============= all threads joined =============\n"
    }
   ],
   "source": [
    "unique_users = final_ratings.userId.unique()\n",
    "\n",
    "# split the dictionary in 2\n",
    "r1, r2 = split_list(unique_users)\n",
    "\n",
    "# split the two dictionaries in 4\n",
    "r11, r12 = split_list(r1)\n",
    "r21, r22 = split_list(r2)\n",
    "\n",
    "# split the 4 dictionaries in 8\n",
    "r1, r2 = split_list(r11)\n",
    "r3, r4 = split_list(r12)\n",
    "r5, r6 = split_list(r21)\n",
    "r7, r8 = split_list(r22)\n",
    "\n",
    "thread1 = CreateUtilityThread('thread-1', unique_users = r1, ratings = final_ratings, job = 'user_based')\n",
    "thread2 = CreateUtilityThread('thread-2', unique_users = r2, ratings = final_ratings, job = 'user_based')\n",
    "thread3 = CreateUtilityThread('thread-3', unique_users = r3, ratings = final_ratings, job = 'user_based')\n",
    "thread4 = CreateUtilityThread('thread-4', unique_users = r4, ratings = final_ratings, job = 'user_based')\n",
    "thread5 = CreateUtilityThread('thread-5', unique_users = r5, ratings = final_ratings, job = 'user_based')\n",
    "thread6 = CreateUtilityThread('thread-6', unique_users = r6, ratings = final_ratings, job = 'user_based')\n",
    "thread7 = CreateUtilityThread('thread-7', unique_users = r7, ratings = final_ratings, job = 'user_based')\n",
    "thread8 = CreateUtilityThread('thread-8', unique_users = r8, ratings = final_ratings, job = 'user_based')\n",
    "\n",
    "threads = [thread1,thread2,thread3,thread4,thread5,thread6,thread7,thread8]\n",
    "\n",
    "[thread.start() for thread in threads]\n",
    "print('============= all threads started =============')\n",
    "\n",
    "dictionaries = [thread.join() for thread in threads]\n",
    "print('============= all threads joined =============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the number of unique_users is 233714 and the sanity check is True\n"
    }
   ],
   "source": [
    "utility_matrix_user_based = {**dictionaries[0],**dictionaries[1],**dictionaries[2],**dictionaries[3],\n",
    "                            **dictionaries[4],**dictionaries[5],**dictionaries[6],**dictionaries[7]}\n",
    "print('the number of unique_users is {} and the sanity check is {}'.format(len(unique_users),len(utility_matrix_user_based) == len(unique_users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "keys must be a string",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-6ace9294f753>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./utility_matrix_user_based.txt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutility_matrix_user_based\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mindent\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mseparators\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m         default is None and not sort_keys and not kw):\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_encoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;31mTypeError\u001b[0m: keys must be a string"
     ]
    }
   ],
   "source": [
    "with open('./utility_matrix_user_based.txt','w') as fw:\n",
    "    json.dump(utility_matrix_user_based, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with  open('./utility_matrix_user_based.txt','r') as fr:\n",
    "    data = json.load(fr)\n",
    "print(len(data), len(data['2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_movies = np.sort(final_ratings.movieId.unique())\n",
    "\n",
    "# split the dictionary in 2\n",
    "r1, r2 = split_list(unique_movies)\n",
    "\n",
    "# split the two dictionaries in 4\n",
    "r11, r12 = split_list(r1)\n",
    "r21, r22 = split_list(r2)\n",
    "\n",
    "# split the 4 dictionaries in 8\n",
    "r1, r2 = split_list(r11)\n",
    "r3, r4 = split_list(r12)\n",
    "r5, r6 = split_list(r21)\n",
    "r7, r8 = split_list(r22)\n",
    "\n",
    "thread1 = CreateUtilityThread('thread-1', unique_items = r1, ratings = final_ratings, job = 'item_based')\n",
    "thread2 = CreateUtilityThread('thread-2', unique_items = r2, ratings = final_ratings, job = 'item_based')\n",
    "thread3 = CreateUtilityThread('thread-3', unique_items = r3, ratings = final_ratings, job = 'item_based')\n",
    "thread4 = CreateUtilityThread('thread-4', unique_items = r4, ratings = final_ratings, job = 'item_based')\n",
    "thread5 = CreateUtilityThread('thread-5', unique_items = r5, ratings = final_ratings, job = 'item_based')\n",
    "thread6 = CreateUtilityThread('thread-6', unique_items = r6, ratings = final_ratings, job = 'item_based')\n",
    "thread7 = CreateUtilityThread('thread-7', unique_items = r7, ratings = final_ratings, job = 'item_based')\n",
    "thread8 = CreateUtilityThread('thread-8', unique_items = r8, ratings = final_ratings, job = 'item_based')\n",
    "\n",
    "threads = [thread1,thread2,thread3,thread4,thread5,thread6,thread7,thread8]\n",
    "\n",
    "[thread.start() for thread in threads]\n",
    "print('============= all threads started =============')\n",
    "\n",
    "dictionaries = [thread.join() for thread in threads]\n",
    "print('============= all threads joined =============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "utility_matrix_item_based = {**dictionaries[0],**dictionaries[1],**dictionaries[2],**dictionaries[3],\n",
    "                            **dictionaries[4],**dictionaries[5],**dictionaries[6],**dictionaries[7]}\n",
    "print('the number of unique_items is {} and the sanity check is {}'.format(len(unique_movies),len(utility_matrix_item_based) == len(unique_movies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./utility_matrix_item_based.txt','w') as fw:\n",
    "    json.dump(utility_matrix_item_based, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "16770\n"
    }
   ],
   "source": [
    "with  open('./utility_matrix_item_based.txt','r') as fr:\n",
    "    data = json.load(fr)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python35964bitd64f83c1351d48cba4de8d31f561fd21",
   "display_name": "Python 3.5.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}