{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import sys \n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_path = os.path.join(os.path.join(os.getcwd(),'Datasets'),'movies_dataset')\n",
    "\n",
    "metadata_path = os.path.join(movies_path,'movies_metadata.csv')\n",
    "ratings_path = os.path.join(movies_path,'ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(metadata_path)\n",
    "ratings = pd.read_csv(ratings_path)\n",
    "\n",
    "ratings = ratings.drop(columns='timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "          userId  movieId  rating\n0              1      110     1.0\n1              1      147     4.5\n2              1      858     5.0\n3              1     1221     5.0\n4              1     1246     5.0\n...          ...      ...     ...\n26024284  270896    58559     5.0\n26024285  270896    60069     5.0\n26024286  270896    63082     4.5\n26024287  270896    64957     4.5\n26024288  270896    71878     2.0\n\n[26024289 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>userId</th>\n      <th>movieId</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>110</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>147</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>858</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1221</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>1246</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26024284</th>\n      <td>270896</td>\n      <td>58559</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>26024285</th>\n      <td>270896</td>\n      <td>60069</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>26024286</th>\n      <td>270896</td>\n      <td>63082</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>26024287</th>\n      <td>270896</td>\n      <td>64957</td>\n      <td>4.5</td>\n    </tr>\n    <tr>\n      <th>26024288</th>\n      <td>270896</td>\n      <td>71878</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>26024289 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "------------------------------------------------------------\nTraceback (most recent call last):\n  File \"<ipython-input-5-44df0911440c>\", line 42, in <module>\n    prod_comp_row = eval(metadata.iloc[index,:].production_companies)\nTypeError: eval() arg 1 must be a string, bytes or code object\n------------------------------------------------------------\n------------------------------------------------------------\nTraceback (most recent call last):\n  File \"<ipython-input-5-44df0911440c>\", line 8, in <module>\n    id_row = int(metadata.iloc[index,:].id)\nValueError: invalid literal for int() with base 10: '1997-08-20'\n------------------------------------------------------------\n------------------------------------------------------------\nTraceback (most recent call last):\n  File \"<ipython-input-5-44df0911440c>\", line 42, in <module>\n    prod_comp_row = eval(metadata.iloc[index,:].production_companies)\nTypeError: eval() arg 1 must be a string, bytes or code object\n------------------------------------------------------------\n------------------------------------------------------------\nTraceback (most recent call last):\n  File \"<ipython-input-5-44df0911440c>\", line 8, in <module>\n    id_row = int(metadata.iloc[index,:].id)\nValueError: invalid literal for int() with base 10: '2012-09-29'\n------------------------------------------------------------\n------------------------------------------------------------\nTraceback (most recent call last):\n  File \"<ipython-input-5-44df0911440c>\", line 42, in <module>\n    prod_comp_row = eval(metadata.iloc[index,:].production_companies)\nTypeError: eval() arg 1 must be a string, bytes or code object\n------------------------------------------------------------\n------------------------------------------------------------\nTraceback (most recent call last):\n  File \"<ipython-input-5-44df0911440c>\", line 8, in <module>\n    id_row = int(metadata.iloc[index,:].id)\nValueError: invalid literal for int() with base 10: '2014-01-01'\n------------------------------------------------------------\n"
    }
   ],
   "source": [
    "nrows = metadata.shape[0]\n",
    "\n",
    "movies = {}\n",
    "for index in range(nrows):\n",
    "\n",
    "    # get the id of the movie\n",
    "    try:\n",
    "        id_row = int(metadata.iloc[index,:].id)\n",
    "    except:\n",
    "        print('-'*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print('-'*60)\n",
    "        continue\n",
    "\n",
    "\n",
    "    # get the genres of the movie\n",
    "    try:\n",
    "         genres_row = eval(metadata.iloc[index,:].genres)\n",
    "         genres_list = []\n",
    "         for genres_dict in genres_row:\n",
    "            id_ = genres_dict['id']\n",
    "            genres_list.append(id_)\n",
    "    except:\n",
    "        print('-'*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print('-'*60)\n",
    "        continue\n",
    "\n",
    "    # get original language\n",
    "    try:\n",
    "         original_row = metadata.iloc[index,:].original_language\n",
    "    except:\n",
    "        print('-'*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print('-'*60)\n",
    "        continue\n",
    "\n",
    "    \n",
    "    # get the production companies\n",
    "    try:\n",
    "        prod_comp_list = []\n",
    "        prod_comp_row = eval(metadata.iloc[index,:].production_companies)\n",
    "        for prod_comp_dict in prod_comp_row:\n",
    "            id_ = prod_comp_dict['id']\n",
    "            prod_comp_list.append(id_)\n",
    "    except:\n",
    "        print('-'*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print('-'*60)\n",
    "        continue\n",
    "\n",
    "    # get the production countries\n",
    "    try:\n",
    "        prod_countries_list = []\n",
    "        prod_countries_row = eval(metadata.iloc[index,:].production_countries)\n",
    "        for prod_countries_dict in prod_countries_row:\n",
    "            country = prod_countries_dict['iso_3166_1']\n",
    "            prod_countries_list.append(country)\n",
    "    except:\n",
    "        print('-'*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print('-'*60)\n",
    "        continue\n",
    "\n",
    "    # get the production countries\n",
    "    try:\n",
    "        spoken_languages_list = []\n",
    "        spoken_languages_row = eval(metadata.iloc[index,:].spoken_languages)\n",
    "        for spoken_languages_dict in spoken_languages_row:\n",
    "            spoken_language = spoken_languages_dict['iso_639_1']\n",
    "            spoken_languages_list.append(spoken_language)\n",
    "    except:\n",
    "        print('-'*60)\n",
    "        traceback.print_exc(file=sys.stdout)\n",
    "        print('-'*60)\n",
    "        continue\n",
    "\n",
    "    movies[id_row] = {'genres':genres_list,\n",
    "                    'original_language':original_row,\n",
    "                    'production_companies':prod_comp_list,\n",
    "                    'production_countries': prod_countries_list,\n",
    "                    'spoken_language':spoken_languages_list}\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "45430"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "len(movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./movies_metadata.txt','w') as fw:\n",
    "    json.dump(movies, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "45430\n"
    }
   ],
   "source": [
    "with  open('./movies_metadata.txt','r') as fr:\n",
    "    data = json.load(fr)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_users(ratings):\n",
    "    # count occurrences of same userId\n",
    "    print(ratings.shape)\n",
    "    ids = ratings.userId\n",
    "    counts = ids.value_counts()\n",
    "\n",
    "    # select ids to keep (users with #ratings >= 5)\n",
    "    to_keep = counts[counts.values >= 10].index\n",
    "    mask = [(x in to_keep) for x in ratings.userId]\n",
    "    ratings_5 = ratings[mask]\n",
    "    return ratings_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_movies(ratings):\n",
    "    # count occurrences of same movieId\n",
    "    print(ratings.shape)\n",
    "    ids = ratings.movieId\n",
    "    counts = ids.value_counts()\n",
    "\n",
    "    # select ids to keep (movies with #ratings >= 20)\n",
    "    to_keep = counts[counts.values >= 20].index\n",
    "    mask = [(x in to_keep) for x in ratings.movieId]\n",
    "    ratings_20 = ratings[mask]\n",
    "    return ratings_20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter(ratings):\n",
    "    num_rows = ratings.shape[0]\n",
    "\n",
    "    tmp = ratings\n",
    "    while True:\n",
    "        tmp_5 = filter_users(tmp)\n",
    "        if tmp_5.shape[0] == tmp.shape[0]:\n",
    "            print('convergence has been reached')\n",
    "            return tmp_5\n",
    "        else:\n",
    "            print('users filtered')\n",
    "            tmp = tmp_5\n",
    "        tmp_20 = filter_movies(tmp)\n",
    "        if tmp_20.shape[0] == tmp.shape[0]:\n",
    "            print('convergence has been reached')\n",
    "            return tmp_20\n",
    "        else:\n",
    "            print('movie filtered')\n",
    "            tmp = tmp_20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(26024289, 3)\nusers filtered\n(25847473, 3)\nmovie filtered\n(25711452, 3)\nusers filtered\n(25709850, 3)\nmovie filtered\n(25709736, 3)\nusers filtered\n(25709727, 3)\nconvergence has been reached\n"
    }
   ],
   "source": [
    "final_ratings = filter(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_user_based_dictionary(unique_users, ratings):\n",
    "    print('\\nunique users in this batch are from {} to {}'.format(unique_users[0], unique_users[-1]))\n",
    "    print('\\nthe shape of ratings is {}'.format(ratings.shape))\n",
    "    sparse_user_based = {}\n",
    "\n",
    "    for user in unique_users:\n",
    "        user_ratings = {}\n",
    "        user_subtable = ratings[ratings.userId == user]\n",
    "        for index,row in user_subtable.iterrows():\n",
    "            user_ratings[str(row['movieId'])] = str(row['rating'])\n",
    "        sparse_user_based[str(user)] = user_ratings\n",
    "        if user%1000 in [0,1]:\n",
    "            print('user is {}'.format(user))\n",
    "    return sparse_user_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_item_based_dictionary(unique_movies, ratings):\n",
    "    print('\\nunique movies in this batch are from {} to {}'.format(unique_movies[0], unique_movies[-1]))\n",
    "    print('\\nthe shape of ratings is {}'.format(ratings.shape))\n",
    "    sparse_item_based = {}\n",
    "\n",
    "    for movie in unique_movies:\n",
    "        movie_ratings = {}\n",
    "        movie_subtable = ratings[ratings.movieId == movie]\n",
    "        for index,row in movie_subtable.iterrows():\n",
    "            movie_ratings[str(row['userId'])] = str(row['rating'])\n",
    "        sparse_item_based[str(movie)] = movie_ratings\n",
    "        if movie%500 in [0,1]:\n",
    "            print('movie is {}'.format(movie))\n",
    "    return sparse_item_based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "\n",
    "class CreateUtilityThread(Thread):\n",
    "    def __init__(self, name = None, unique_users = None, unique_items = None, ratings = None, job = None):\n",
    "        Thread.__init__(self)\n",
    "        self.name = name\n",
    "        self.unique_users = unique_users\n",
    "        self.unique_items = unique_items\n",
    "        self.ratings = ratings\n",
    "        self.job = job\n",
    "        self._return = None\n",
    "\n",
    "    def run(self):\n",
    "        print(self.name)\n",
    "        if self.name is not None:\n",
    "            if self.job == 'item_based':\n",
    "                self._return = build_item_based_dictionary(self.unique_items, self.ratings)\n",
    "            elif self.job == 'user_based':\n",
    "                self._return = build_user_based_dictionary(self.unique_users, self.ratings)\n",
    "            else:\n",
    "                print('Error, you have to specify a job')\n",
    "\n",
    "    def join(self):\n",
    "        Thread.join(self)\n",
    "        if self._return is not None:\n",
    "            return self._return\n",
    "        else:\n",
    "            print('Error using threading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(l):\n",
    "    n = len(l) // 2          # length of smaller half\n",
    "    \n",
    "    l1 = l[:n]\n",
    "    l2 = l[n:]\n",
    "\n",
    "    return l1, l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "thread-1thread-2\nthread-3\n\nunique users in this batch are from 67770 to 101724\n\nthe shape of ratings is (25709727, 3)\nthread-4\n\nunique users in this batch are from 101725 to 135636\n\nthe shape of ratings is (25709727, 3)thread-5\n\nunique users in this batch are from 135637 to 169389\n\nthe shape of ratings is (25709727, 3)\n\n\n\nunique users in this batch are from 1 to 34009\n\nthe shape of ratings is (25709727, 3)\nthread-6thread-7\n\nunique users in this batch are from 203208 to 236978\n\nthe shape of ratings is (25709727, 3)\nthread-8\n\nunique users in this batch are from 236979 to 270896\n\nthe shape of ratings is (25709727, 3)\n\nunique users in this batch are from 34010 to 67769============= all threads started =============\n\n\nunique users in this batch are from 169394 to 203207\n\nthe shape of ratings is (25709727, 3)\n\n\nthe shape of ratings is (25709727, 3)\nuser is 1\nuser is 237000\nuser is 237001\nuser is 68000\nuser is 68001\nuser is 102000\nuser is 102001\nuser is 136000\nuser is 136001\nuser is 170001\nuser is 204000\nuser is 204001\nuser is 35000\nuser is 35001\nuser is 1001\nuser is 238000\nuser is 238001\nuser is 69000\nuser is 69001\nuser is 103000\nuser is 103001\nuser is 137000\nuser is 137001\nuser is 171000\nuser is 171001\nuser is 205000\nuser is 205001\nuser is 36001\nuser is 2000\nuser is 2001\nuser is 239001\nuser is 70001\nuser is 104000\nuser is 104001\nuser is 138000\nuser is 138001\nuser is 172000\nuser is 172001\nuser is 206000\nuser is 3000\nuser is 3001\nuser is 37000\nuser is 37001\nuser is 71001\nuser is 105000\nuser is 139000\nuser is 139001\nuser is 173000\nuser is 173001\nuser is 207000\nuser is 207001\nuser is 4000\nuser is 4001\nuser is 38001\nuser is 241001\nuser is 72000\nuser is 106000\nuser is 106001\nuser is 140000\nuser is 140001\nuser is 174000\nuser is 174001\nuser is 208000\nuser is 208001\nuser is 5000\nuser is 5001\nuser is 39000\nuser is 39001\nuser is 242000\nuser is 242001\nuser is 73000\nuser is 73001\nuser is 107000\nuser is 107001\nuser is 141000\nuser is 141001\nuser is 175000\nuser is 175001\nuser is 209000\nuser is 209001\nuser is 40000\nuser is 40001\nuser is 243000\nuser is 243001\nuser is 74000\nuser is 74001\nuser is 108000\nuser is 108001\nuser is 142000\nuser is 142001\nuser is 176000\nuser is 176001\nuser is 210000\nuser is 210001\nuser is 41000\nuser is 7000\nuser is 7001\nuser is 244000\nuser is 244001\nuser is 75000\nuser is 75001\nuser is 109000\nuser is 109001\nuser is 143000\nuser is 143001\nuser is 177000\nuser is 211000\nuser is 211001\nuser is 8000\nuser is 42000\nuser is 8001\nuser is 42001\nuser is 245000\nuser is 245001\nuser is 76000\nuser is 76001\nuser is 110000\nuser is 110001\nuser is 144000\nuser is 144001\nuser is 178000\nuser is 178001\nuser is 212000\nuser is 212001\nuser is 9000\nuser is 43000\nuser is 43001\nuser is 246000\nuser is 246001\nuser is 77000\nuser is 77001\nuser is 111000\nuser is 111001\nuser is 145000\nuser is 145001\nuser is 179000\nuser is 213000\nuser is 213001\nuser is 10001\nuser is 44000\nuser is 44001\nuser is 247000\nuser is 247001\nuser is 78000\nuser is 78001\nuser is 112000\nuser is 112001\nuser is 146000\nuser is 146001\nuser is 180000\nuser is 180001\nuser is 214000\nuser is 214001\nuser is 11000\nuser is 11001\nuser is 45000\nuser is 45001\nuser is 248000\nuser is 79000\nuser is 79001\nuser is 113000\nuser is 113001\nuser is 147001\nuser is 181000\nuser is 181001\nuser is 215000\nuser is 12000\nuser is 12001\nuser is 46000\nuser is 46001\nuser is 249000\nuser is 114001\nuser is 80000\nuser is 80001\nuser is 148000\nuser is 148001\nuser is 182000\nuser is 182001\nuser is 216000\nuser is 216001\nuser is 13000\nuser is 13001\nuser is 47000\nuser is 47001\nuser is 250000\nuser is 250001\nuser is 115000\nuser is 115001\nuser is 81000\nuser is 81001\nuser is 149000\nuser is 183000\nuser is 183001\nuser is 217000\nuser is 217001\nuser is 14000\nuser is 14001\nuser is 251000\nuser is 251001\nuser is 48000\nuser is 48001\nuser is 116000\nuser is 116001\nuser is 82000\nuser is 82001\nuser is 150000\nuser is 150001\nuser is 184001\nuser is 218001\nuser is 15000\nuser is 49000\nuser is 49001\nuser is 252000\nuser is 252001\nuser is 117000\nuser is 117001\nuser is 83000\nuser is 83001\nuser is 151000\nuser is 185000\nuser is 185001\nuser is 219000\nuser is 16000\nuser is 16001\nuser is 50000\nuser is 50001\nuser is 253000\nuser is 118001\nuser is 84000\nuser is 152001\nuser is 186000\nuser is 186001\nuser is 220000\nuser is 220001\nuser is 17000\nuser is 17001\nuser is 254000\nuser is 254001\nuser is 51000\nuser is 51001\nuser is 153000\nuser is 153001\nuser is 187000\nuser is 187001\nuser is 221001\nuser is 18000\nuser is 18001\nuser is 52000\nuser is 52001\nuser is 255000\nuser is 255001\nuser is 120000\nuser is 120001\nuser is 86000\nuser is 86001\nuser is 154000\nuser is 154001\nuser is 188000\nuser is 188001\nuser is 222000\nuser is 222001\nuser is 19000\nuser is 19001\nuser is 53000\nuser is 256000\nuser is 256001\nuser is 121000\nuser is 121001\nuser is 87000\nuser is 87001\nuser is 155000\nuser is 155001\nuser is 189000\nuser is 189001\nuser is 223000\nuser is 223001\nuser is 20000\nuser is 54000\nuser is 54001\nuser is 257000\nuser is 257001\nuser is 122001\nuser is 88001\nuser is 156000\nuser is 190000\nuser is 190001\nuser is 224000\nuser is 21000\nuser is 21001\nuser is 55000\nuser is 55001\nuser is 258000\nuser is 258001\nuser is 123000\nuser is 123001\nuser is 89001\nuser is 157000\nuser is 157001\nuser is 191000\nuser is 191001\nuser is 225000\nuser is 225001\nuser is 22000\nuser is 22001\nuser is 56000\nuser is 56001\nuser is 259000\nuser is 259001\nuser is 124000\nuser is 124001\nuser is 90000\nuser is 90001\nuser is 158000\nuser is 158001\nuser is 192000\nuser is 192001\nuser is 226000\nuser is 226001\nuser is 23000\nuser is 23001\nuser is 260000\nuser is 57000\nuser is 57001\nuser is 125000\nuser is 125001\nuser is 91000\nuser is 91001\nuser is 159000\nuser is 159001\nuser is 193000\nuser is 193001\nuser is 227000\nuser is 227001\nuser is 24000\nuser is 24001\nuser is 261000\nuser is 261001\nuser is 58000\nuser is 58001\nuser is 126000\nuser is 126001\nuser is 92001\nuser is 160001\nuser is 194000\nuser is 25001\nuser is 228000\nuser is 228001\nuser is 262001\nuser is 59000\nuser is 59001\nuser is 93000\nuser is 161000\nuser is 161001\nuser is 195000\nuser is 195001\nuser is 26001\nuser is 229000\nuser is 229001\nuser is 263000\nuser is 263001\nuser is 60000\nuser is 60001\nuser is 128000\nuser is 128001\nuser is 94000\nuser is 94001\nuser is 162000\nuser is 162001\nuser is 196000\nuser is 196001\nuser is 27000\nuser is 27001\nuser is 264000\nuser is 230000\nuser is 230001\nuser is 61000\nuser is 61001\nuser is 129000\nuser is 129001\nuser is 95000\nuser is 95001\nuser is 163000\nuser is 163001\nuser is 197000\nuser is 197001\nuser is 28000\nuser is 28001\nuser is 265000\nuser is 265001\nuser is 231001\nuser is 62000\nuser is 62001\nuser is 130000\nuser is 130001\nuser is 96001\nuser is 164000\nuser is 164001\nuser is 198000\nuser is 198001\nuser is 29000\nuser is 29001\nuser is 266000\nuser is 232000\nuser is 232001\nuser is 63000\nuser is 63001\nuser is 131000\nuser is 97000\nuser is 165000\nuser is 165001\nuser is 199001\nuser is 30000\nuser is 30001\nuser is 267000\nuser is 267001\nuser is 233000\nuser is 233001\nuser is 64000\nuser is 64001\nuser is 132000\nuser is 132001\nuser is 98000\nuser is 98001\nuser is 166000\nuser is 166001\nuser is 200000\nuser is 200001\nuser is 31000\nuser is 31001\nuser is 234000\nuser is 234001\nuser is 268000\nuser is 268001\nuser is 65000\nuser is 133000\nuser is 133001\nuser is 99000\nuser is 99001\nuser is 167000\nuser is 167001\nuser is 201001\nuser is 32001\nuser is 235000\nuser is 235001\nuser is 269001\nuser is 66000\nuser is 66001\nuser is 134000\nuser is 100000\nuser is 100001\nuser is 168000\nuser is 168001\nuser is 202001\nuser is 33000\nuser is 33001\nuser is 236001\nuser is 270000\nuser is 270001\nuser is 67000\nuser is 67001\nuser is 135001\nuser is 101000\nuser is 101001\nuser is 169000\nuser is 203000\nuser is 203001\nuser is 34000\nuser is 34001\n============= all threads joined =============\n"
    }
   ],
   "source": [
    "unique_users = final_ratings.userId.unique()\n",
    "\n",
    "# split the dictionary in 2\n",
    "r1, r2 = split_list(unique_users)\n",
    "\n",
    "# split the two dictionaries in 4\n",
    "r11, r12 = split_list(r1)\n",
    "r21, r22 = split_list(r2)\n",
    "\n",
    "# split the 4 dictionaries in 8\n",
    "r1, r2 = split_list(r11)\n",
    "r3, r4 = split_list(r12)\n",
    "r5, r6 = split_list(r21)\n",
    "r7, r8 = split_list(r22)\n",
    "\n",
    "thread1 = CreateUtilityThread('thread-1', unique_users = r1, ratings = final_ratings, job = 'user_based')\n",
    "thread2 = CreateUtilityThread('thread-2', unique_users = r2, ratings = final_ratings, job = 'user_based')\n",
    "thread3 = CreateUtilityThread('thread-3', unique_users = r3, ratings = final_ratings, job = 'user_based')\n",
    "thread4 = CreateUtilityThread('thread-4', unique_users = r4, ratings = final_ratings, job = 'user_based')\n",
    "thread5 = CreateUtilityThread('thread-5', unique_users = r5, ratings = final_ratings, job = 'user_based')\n",
    "thread6 = CreateUtilityThread('thread-6', unique_users = r6, ratings = final_ratings, job = 'user_based')\n",
    "thread7 = CreateUtilityThread('thread-7', unique_users = r7, ratings = final_ratings, job = 'user_based')\n",
    "thread8 = CreateUtilityThread('thread-8', unique_users = r8, ratings = final_ratings, job = 'user_based')\n",
    "\n",
    "threads = [thread1,thread2,thread3,thread4,thread5,thread6,thread7,thread8]\n",
    "\n",
    "[thread.start() for thread in threads]\n",
    "print('============= all threads started =============')\n",
    "\n",
    "dictionaries = [thread.join() for thread in threads]\n",
    "print('============= all threads joined =============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the number of unique_users is 233714 and the sanity check is True\n"
    }
   ],
   "source": [
    "utility_matrix_user_based = {**dictionaries[0],**dictionaries[1],**dictionaries[2],**dictionaries[3],\n",
    "                            **dictionaries[4],**dictionaries[5],**dictionaries[6],**dictionaries[7]}\n",
    "print('the number of unique_users is {} and the sanity check is {}'.format(len(unique_users),len(utility_matrix_user_based) == len(unique_users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./utility_matrix_user_based.txt','w') as fw:\n",
    "    json.dump(utility_matrix_user_based, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with  open('./utility_matrix_user_based.txt','r') as fr:\n",
    "    data = json.load(fr)\n",
    "print(len(data), len(data['2']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "thread-1thread-2\n\nunique movies in this batch are from 2218 to 4393\n\nthe shape of ratings is (25709727, 3)thread-3\n\nunique movies in this batch are from 4394 to 6615\n\nthe shape of ratings is (25709727, 3)\n\n\nunique movies in this batch are from 1 to 2216\nthread-4\n\nunique movies in this batch are from 6616 to 26693\n\nthe shape of ratings is (25709727, 3)\n\nthe shape of ratings is (25709727, 3)thread-5\n\nunique movies in this batch are from 26694 to 54372\n\nthe shape of ratings is (25709727, 3)\n\n\nthread-6\n\nunique movies in this batch are from 54378 to 81639\n\nthe shape of ratings is (25709727, 3)\nthread-7\n\nunique movies in this batch are from 81641 to 110451\n\nthe shape of ratings is (25709727, 3)\nthread-8============= all threads started =============\n\n\nunique movies in this batch are from 110453 to 175281\n\nthe shape of ratings is (25709727, 3)\nmovie is 110501\nmovie is 1\nmovie is 112501\nmovie is 4500\nmovie is 4501\nmovie is 56001\nmovie is 113501\nmovie is 114001\nmovie is 86000\nmovie is 31000\nmovie is 89000\nmovie is 7000\nmovie is 7001\nmovie is 59000\nmovie is 32501\nmovie is 59501\nmovie is 91500\nmovie is 133001\nmovie is 92500\nmovie is 62000\nmovie is 136501\nmovie is 63001\nmovie is 2500\nmovie is 64501\nmovie is 2501\nmovie is 5000\nmovie is 5001\nmovie is 65001\nmovie is 96501\nmovie is 151501\nmovie is 156000\nmovie is 45000\nmovie is 45501\nmovie is 8500\nmovie is 8501\nmovie is 71500\nmovie is 48001\nmovie is 73000\nmovie is 107000\nmovie is 5500\nmovie is 5501\nmovie is 48501\nmovie is 108501\nmovie is 9000\nmovie is 9001\nmovie is 53000\nmovie is 26501\nmovie is 54001\nmovie is 6000\nmovie is 6001\nmovie is 3000\nmovie is 3001\nmovie is 6500\nmovie is 500\nmovie is 501\nmovie is 3500\nmovie is 3501\nmovie is 4000\nmovie is 4001\nmovie is 1000\nmovie is 1001\nmovie is 1500\nmovie is 1501\nmovie is 2000\nmovie is 2001\n============= all threads joined =============\n"
    }
   ],
   "source": [
    "unique_movies = np.sort(final_ratings.movieId.unique())\n",
    "\n",
    "# split the dictionary in 2\n",
    "r1, r2 = split_list(unique_movies)\n",
    "\n",
    "# split the two dictionaries in 4\n",
    "r11, r12 = split_list(r1)\n",
    "r21, r22 = split_list(r2)\n",
    "\n",
    "# split the 4 dictionaries in 8\n",
    "r1, r2 = split_list(r11)\n",
    "r3, r4 = split_list(r12)\n",
    "r5, r6 = split_list(r21)\n",
    "r7, r8 = split_list(r22)\n",
    "\n",
    "thread1 = CreateUtilityThread('thread-1', unique_items = r1, ratings = final_ratings, job = 'item_based')\n",
    "thread2 = CreateUtilityThread('thread-2', unique_items = r2, ratings = final_ratings, job = 'item_based')\n",
    "thread3 = CreateUtilityThread('thread-3', unique_items = r3, ratings = final_ratings, job = 'item_based')\n",
    "thread4 = CreateUtilityThread('thread-4', unique_items = r4, ratings = final_ratings, job = 'item_based')\n",
    "thread5 = CreateUtilityThread('thread-5', unique_items = r5, ratings = final_ratings, job = 'item_based')\n",
    "thread6 = CreateUtilityThread('thread-6', unique_items = r6, ratings = final_ratings, job = 'item_based')\n",
    "thread7 = CreateUtilityThread('thread-7', unique_items = r7, ratings = final_ratings, job = 'item_based')\n",
    "thread8 = CreateUtilityThread('thread-8', unique_items = r8, ratings = final_ratings, job = 'item_based')\n",
    "\n",
    "threads = [thread1,thread2,thread3,thread4,thread5,thread6,thread7,thread8]\n",
    "\n",
    "[thread.start() for thread in threads]\n",
    "print('============= all threads started =============')\n",
    "\n",
    "dictionaries = [thread.join() for thread in threads]\n",
    "print('============= all threads joined =============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "the number of unique_items is 16770 and the sanity check is True\n"
    }
   ],
   "source": [
    "utility_matrix_item_based = {**dictionaries[0],**dictionaries[1],**dictionaries[2],**dictionaries[3],\n",
    "                            **dictionaries[4],**dictionaries[5],**dictionaries[6],**dictionaries[7]}\n",
    "print('the number of unique_items is {} and the sanity check is {}'.format(len(unique_movies),len(utility_matrix_item_based) == len(unique_movies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./utility_matrix_item_based.txt','w') as fw:\n",
    "    json.dump(utility_matrix_item_based, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "16770\n"
    }
   ],
   "source": [
    "with  open('./utility_matrix_item_based.txt','r') as fr:\n",
    "    data = json.load(fr)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python35964bitd64f83c1351d48cba4de8d31f561fd21",
   "display_name": "Python 3.5.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}